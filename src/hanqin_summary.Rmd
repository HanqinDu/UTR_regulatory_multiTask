---
title: "project summary"
author: "Hanqin Du"
date: "2020/2/1"
output: html_document
---


```{r set work space for r, eval=FALSE, echo=FALSE}
# set work space for Rstudio
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

# recent progress (2020/02/19 ~ 2020/02/25)
This week, we [validated the performance of kNN](#imputation) with a range of values of k by randomly knocking out 0.1% of non-NA values, filling by imputation and computing the mean square error. According to the validation, k = 11 provides the best performance with estimate mean square error = 0.1840177 which is similar to that of k = 8. We considered k = 11 as a more conserved chosen for the hyperparameter for kNN imputation.

To compare the coefficient between models, we calculated and [compare the L2 norm of all the non-zero coefficient](#L2Allcondition) of each significant motif. Then we [divide some models into small groups](#environmentalGroup) and calculate the L2 norm and summing of motifs' coefficients in each group. As a simple attempt, we compare the L2 norm and summing of coefficients from [(1)](#heatShockHypothermia) the group "heat shock from 25C to 37C" and group "hypothermia from 37C to 25C"; [(2)](#heatShocksorbitol) the group "heat shock from 29C to 33C" and group "heat shock with sorbitol from 29C to 33C". To keep the consistency and comparability of the selection models, for the first two groups, only three models predict gene expression 15, 30 and 60 mins after the environmental stress are considered. For the other two groups, only three models predict gene expression 5, 15 and 30 mins after the environmental stress are considered.


# project discription
Gene expression is the process through which cells generate diversity and resilience to environmental changes. It consists of two steps: transcription, where an intermediate molecule (mRNA) is produced from the DNA, and translation of mRNA into protein. The rate of transcription and translation can be regulated by regulatory elements acting in both cis and trans. 3'UTR, 5'UTR, and promoter are known as powerful regulatory processes that determine the rate of mRNA synthesis and decay.

In this project, we are interested in using these cis-regulatory features to predict multidimensional output that indicates how the mRNA abundance change in multiple environmental conditions. Since our goal is to quantify the effect of different elements, we should avoid clustering and go straight from element to expression pattern. Linear models with multidimensional lasso (known as an algorithm of multi-task learning) which is already implemented in the glmnet package should be a good start. As an extension, we may apply to multiple states of mRNA processing like splicing, decay, and translation by combining multiple data sets. Finally, we can carry out a quantitative analysis of the contribution of motifs in different types of CRE and ask which regions make more of a contribution to dynamic changes in gene expression.



# Index

- ### Part 1: Assess the rationality of group lasso

  - [Load library and function](#loadFunction)
  - [Construct the design matrix](#constructDesignMatrix)
  - [19 motifs are removed from list considering their low frequency on 3’UTR](#removeLowFrequencyMotifs)
  - [4 significant motifs on heat-shock-relevant environmental stress](#significantMotifsHS)
  - [9 heat-shock-relevant motifs are selected from linear models](#9significantMotifsHS)
  - [Identify potential relationships between tasks](#potentialRelationshipTask)

- ### Part 2: apply group lasso

  - dealing with missing value
    - [distribution of missing value](#distributionMissingValue)
    - [filter out gene with high value-missing ratio](#filterGene)
    - [fill missing value by kNN imputation](#imputation)
    - [baseline: replace missing value with 0](#replaceZero)
  - fitting models
    - [choose lambda from 10-fold cross validation](#crossValidation)
    - [training model with selected lambda](#trainingModels)
  - evaluate models
    - [regulatory effect of motifs decrease as time pass in heat shock](#regulatoryEffectDecrease)
    
- ### Part 3: analyze the regression coefficients

  - comparison between L2 norm and sum of the non-zero regression coefficients
    - [divide environmental condition into groups](#environmentalGroup)
    - [under all condition](#L2Allcondition)
    - [under heat shock and hypothermia](#heatShockHypothermia)
    - [under heat shock with and without sorbitol](#heatShocksorbitol)


# Part 1: Assess the rationality of group lasso
This is the first part of this project. Before applying multi-task learning, we would like to investigate the data and assess if it is reasonable to apply group lasso on them.


### <a id="loadFunction"> Load library and function </a>

```{r load library, results='hide', message=FALSE}
library(data.table)
library(tidyverse)
library(lmodel2)
library(splitstackshape)
library(gridExtra)
library(glmnet)
library(impute)
```


```{r load function, echo=FALSE}

# obtain mean square error from a linear model
mse <- function(model){
  mean(summary(model)$residuals^2)
}

# plot graph with error bar by value and deviation
plot_mean_deviation <- function(dataset,label,mean,deviation){
  plot(1:dim(dataset)[1],dataset[[mean]], pch=19,xlab="",ylab="coefficient",xaxt="n",xlim = c(0.5,dim(dataset)[1]+0.5),
       ylim=c(min(dataset[mean]-1.96*dataset[deviation]),max((dataset[mean]+1.96*dataset[deviation]))))
  lines(rbind(1:dim(dataset)[1],1:dim(dataset)[1],NA),rbind(dataset[[mean]]-1.96*dataset[[deviation]],dataset[[mean]]+1.96*dataset[[deviation]],NA))
  axis(side=1,at=1:dim(dataset)[1],labels=dataset[[label]])
}

# extract coefficients from selected models
extract_coefficient <- function(models, conditions) {
  coefficients = NULL
  
  for (condition in conditions) {
    column = numeric(models$beta[[condition]]@Dim[1])
    column[models$beta[[condition]]@i+1] = models$beta[[condition]]@x
    coefficients = cbind(coefficients,column)
  }
  coefficients = as.data.frame(coefficients)
  names(coefficients) = conditions
  row.names(coefficients) = names_motifs_valid
  return(melt(setDT(coefficients, keep.rownames = TRUE), "rn"))
}

# plot selected models coefficient with line graph
plot_models_line <- function(models, conditions, lineNumber) {
  coefficients = NULL
  
  for (condition in conditions) {
    column = numeric(models$beta[[condition]]@Dim[1])
    column[models$beta[[condition]]@i+1] = models$beta[[condition]]@x
    coefficients = cbind(coefficients,column)
  }
  coefficients = as.data.frame(coefficients)
  names(coefficients) = conditions
  row.names(coefficients) = names_motifs_valid
  melt(setDT(coefficients, keep.rownames = TRUE), "rn")
  
  i = 1
  while (i <= dim(coefficients)[1]) {
    if((i+lineNumber)<= dim(coefficients)[1]){
      print(
      ggplot(data = melt(setDT(coefficients[i:(i+lineNumber-1)], keep.rownames = TRUE), "rn"), aes(x=variable,y=value,group = rn)) + 
        geom_line(aes(colour=rn))+
        labs(x = "model", y = "regression coefficient") +
        theme(axis.text.x = element_text(size = 16, angle = 60, hjust = 1),axis.text.y = element_text(size = 16),axis.title=element_text(size=16,face="bold"))
      )
    }else{
      print(
      ggplot(data = melt(setDT(coefficients[i:dim(coefficients)[1]], keep.rownames = TRUE), "rn"), aes(x=variable,y=value,group = rn)) + 
        geom_line(aes(colour=rn))+
        labs(x = "model", y = "regression coefficient") +
        theme(axis.text.x = element_text(size = 16, angle = 60, hjust = 1), axis.text.y = element_text(size = 16),axis.title=element_text(size=16,face="bold"))
      )
    }
    
    i = i + lineNumber
  }
  
}


```


### <a id="constructDesignMatrix"> Construct the design matrix </a>

##### Expression level change of 6152 distinct genes under 173 different environmental stresses from Gasch's study
In this project, we apply the data describes gene expression level in various environment condition from Gasch's study `Genomic Expression Programs in the Response of Yeast Cells to Environmental Changes`. To figure out how the expression level change, DNA microarrays were used to measure the relatively abundance of mRNA before and after a series of environmental stresses.


##### The 69 candidate sequence motifs we use in this project is from 3 different studies:

(1) 53 of them come from the study of Shalgi et al (2005). The candidate motifs are derived by analyzing the exhaustively enumerating all k-mers(k = {8,9,10,11,12}) and looking for over-represented motifs with extreme half-life value. For the k-mers method, 515 significant k-mers are selected with ranksum test and clustered by ClustalW which resulted in 51 clusters of motifs. on the other hand, 2 more motifs are found by grouping genes with extreme half-life and ran Gibbs sampler.

(2) 14 of them come from the study of Hogan et al. (2008) who have applied two related computational methods to identify candidates for the binding sites of 40 out of the more than 500 known and predicted RBPs in S. cerevisiae: (1)“finding informative regulatory elements” (FIRE) and (2)“relative filtering by nucleotide enrichment” (REFINE). The previous one searches for motifs with informative patterns of enrichment and the other one identifies all hexamers that are significantly enriched in untranslated regions, filters out regions of target sequences that are relatively devoid of such hexamers, and then applies the “multiple expectation maximization for motif elicitation” (MEME) motif-finding algorithm. As a result, 14 motifs that are likely to be the binding sites of 16 RBP are found.
  
(3) The rest 4 are from the study of Cheng (2017), four mRNA-stability related motifs in the 3′ UTR are found by De novo motif searching and their reliability and effect have been examined by linear mixed effect model, Fisher test P-value corrected with Benjamini–Hochberg, Wilcoxon rank-sum test and multivariate linear regression.

##### UTR sequence of 4388 genes from Sun et al. (2013)
UTR sequence of 4388 genes are obtained from Sun, M. et al. (2013) ‘Global analysis of Eukaryotic mRNA degradation reveals Xrn1-dependent buffering of transcript levels’. 


```{r Load Data, echo=FALSE, warning=FALSE, message=FALSE}

#ref datasets for UTRs 
UTR_raw <- read_rds("../data/Sun_mutation_UTRs.rds")
  #Get sequences from UTR_raw in a separate vector
  UTR_3 <- UTR_raw$UTR3_seq

#Load Manually created motifs list into a vector
motifs_raw <- scan("../data/list_motifs.txt", character())
motifs_cheng = c("TGTAAATA", "TGCAT", "TTTTTTA", "ATATTC")


# load Gasch's data
expressionLevel_Gasch <- read_tsv("../data/Gasch2000_complete_dataset_rename.txt", 
                       locale = locale(decimal = ","))

# convert all the expression data to number
for (i in names(expressionLevel_Gasch)[3:176]) {
  expressionLevel_Gasch[[i]] <- as.numeric(as.character(expressionLevel_Gasch[[i]]))
}

```

```{r construct motif frequency, echo=FALSE}

#Dictionary for non-specific codes and converting U -> T
motifs <- motifs_raw %>% str_replace_all(c("U" = "T", "W" = "(A|T)", "S" = "(C|G)", "M" = "(A|C)", "K" = "(G|T)", "R" = "(A|G)", "Y" = "(C|T)", "B" = "(C|G|T)", "D" = "(A|G|T)", "H" = "(A|C|T)", "V" = "(A|C|G)", "N" = "(A|C|G|T)"))

#Initate ref tibble and store gene names
ref_motifs <- tibble(geneName = UTR_raw$genename)


#Search and add frequency of each c(motif) as a column in ref dataset
for (i in 1:length(motifs)){
  ref_motifs <- mutate(.data = ref_motifs,!!motifs_raw[i] := str_count(UTR_3, motifs[i]))
}

names_motifs_all = names(ref_motifs)[2:length(ref_motifs)]
names_environmental_stress = names(expressionLevel_Gasch)[4:length(expressionLevel_Gasch)]

```


```{r merge motifs frequency with gasch data, echo=FALSE}

# merge motifs
fullTable_Gasch <- merge(expressionLevel_Gasch,ref_motifs,by = "geneName")

# convert type of motifs frequency to factor for violin plotting
fullTable_Gasch_factor = fullTable_Gasch
for(i in names_motifs_all){
    fullTable_Gasch_factor[[i]] <- as.factor(as.character(fullTable_Gasch_factor[[i]]))
}

```




### <a id="removeLowFrequencyMotifs"> 19 motifs are removed from list considering their low frequency on 3'UTR </a>
We matching the 69 motifs on every gene sequence to compute the frequency matrix which could be used as the design matrix of our models. The distribution of the frequency of each motif across all the genes is very unbalanced. 19 motifs have never been investigated from any of the 3'UTR from the study of Sun et al. Therefore, we temporarily remove them.

| Frequency  | number of motifs (n) |
| ---------- | -------------------- |
| n = 0      | 19                   |
| 0 < n < 6  | 17                   |
| 5 < n < 21 | 12                   |
| n > 20     | 21                   |

One possible explanation of the huge amount of low-frequency motifs is that it is hard to match exactly the regular expression to the UTR sequence. Another point is, the secondary-structure motifs are more likely to be found on 5'UTR rather than 3'UTR. Also, a motif with a significant effect on regulation is reasonable to have a small frequency. 


```{r echo=FALSE}
# construct the motif frequency table
motifs_count_sum <- colSums(fullTable_Gasch[names_motifs_all],na.rm=TRUE)

# summary of the table
summary(motifs_count_sum)

# plot histgram
hist(motifs_count_sum, xlim = c(0,20), breaks = c(0,1,2,3,5,10,20,30,8000), main = 'histogram of motifs frequency sum')

# remove zero-frequency motifs from list
remove_list = NULL
for (i in names(motifs_count_sum)){
  if (motifs_count_sum[[i]] == 0){
    remove_list <- c(remove_list,i)
  }
}
names_motifs_valid <- names_motifs_all[!names_motifs_all %in% remove_list]
```




### <a id="significantMotifsHS"> 4 significant motifs on heat-shock-relevant environmental stress.</a>
To investigate how the expression level changes linearly depends on the motifs, we calculate the Pearson correlation coefficient (PCC) between them. Pearson correlation coefficient is a measure of the linear correlation between two variables X and Y:
$$
p_{x,y}= {cov(X,Y)\over \sigma_X \sigma_Y}
$$
We start by picking a group of environmental conditions about Heat Shock from Various Temperatures to 37°C. Four motifs show a much higher correlation coefficient rather than the others, which, indicate the linear relationship between these motifs and expression level. One point worth mentioning is that all these motifs are also focused by Abhi where `TGTATAWT` is explained to be positively associated with RNA stability and the rest three of them are explained to be negatively associated with the RNA stability. However, Abhi is not quite confident with the conclusion of `UGUAHMNUA` as the negative relationship can only be derived from Chan's data but not Sun's data. 


```{r}
names_temperature_condition = vector(mode="character", length=5)
names_temperature_condition[1] = "hs_17to37_20min"
names_temperature_condition[2] = "hs_21to37_20min"
names_temperature_condition[3] = "hs_25to37_20min"
names_temperature_condition[4] = "hs_29to37_20min"
names_temperature_condition[5] = "hs_33to37_20min"
```

```{r echo=FALSE}
# compute correlation coefficient
motif_overview <- as.data.frame(
  cor(fullTable_Gasch[names_motifs_valid],fullTable_Gasch[names_temperature_condition], use = "na.or.complete"))

# compute mean
motif_overview$R_mean <- rowMeans(motif_overview[names_temperature_condition[1:5]])

```

```{r, echo=FALSE, fig.width=10, fig.height=7}
## plot motifs with high correlation coefficient
ggplot(data = melt(setDT(as.data.frame(motif_overview[c('UGUAHMNUA','TGTATAWT','ATATTC','TGTAAATA'),names_temperature_condition]), keep.rownames = TRUE), "rn"), aes(x=variable,y=value,group = rn)) + 
  geom_line(aes(colour=rn),size=2) + 
  ylim(-0.25,0.1) + 
  labs(x = "heat shock to 37C from", y = "correlation coefficient") +
  scale_x_discrete(labels=c("hs_17to37_20min" = "17C", "hs_21to37_20min" = "21C","hs_25to37_20min" = "25C","hs_29to37_20min" = "29C", "hs_33to37_20min" = "33C")) + 
  theme(text = element_text(size=24))
```


### <a id="9significantMotifsHS"> 9 heat-shock-relevant motifs are selected from linear models </a>

Before fitting the linear model, we temporarily remove the motifs with a total frequency lower than 5 since we are not confident enough to tell whether a low-frequency motif depends linearly on the heat-shock related environment condition. Then, we fitted the linear model with the `lm()` function with default least squares method:
$$
\min_w \sum (w*e)^2
$$

```{r echo=FALSE}
# filter out motif with frequency lower than or equal to 5
remove_list = NULL

for (i in names(motifs_count_sum)){
  if (motifs_count_sum[[i]] < 6){
    remove_list <- c(remove_list,i)
  }
}

names_motifs_valid <- names_motifs_all[!names_motifs_all %in% remove_list]
```


```{r echo=FALSE}
# linear regression on heat shock from 17C to 37C
formula_model_hs_17to37 <- as.formula(paste("hs_17to37_20min ~",paste(names_motifs_valid, collapse = "+")))
model_hs_17to37 = lm(formula_model_hs_17to37,fullTable_Gasch)

par(mfrow=c(2,2))
plot(model_hs_17to37)
print("mean square error:")
mse(model_hs_17to37)
```


 9 heat-shock-relevant motifs are selected from the linear model with the following coefficient:
 
 
| Motif      | Estimate | Std.Error | t value | Pr(>\|t\|) |
| ---------- | -------- | --------- | ------- | ---------- |
| UGUAHMNUA  | -1.054   | 0.085     | -12.369 | <2e-16     |
| ATATTC     | 0.309    | 0.057     | 5.432   | 5.90e-08   |
| TGTATAWT   | -0.468   | 0.095     | -4.907  | 9.62e-07   |
| WUUGUAWUWU | -0.534   | 0.157     | -3.413  | 0.0006     |
| UAAUAAUW   | -0.250   | 0.083     | -3.025  | 0.0025     |
| TGTAAATA   | 0.244    | 0.106     | 2.308   | 0.0211     |
| AAAATAAAG  | -0.568   | 0.281     | -2.018  | 0.0436     |
| UUUAAUGA   | 0.302    | 0.162     | 1.864   | 0.0624     |
| TCATGTAT   | -0.327   | 0.207     | -1.580  | 0.1141     |


This table is sorted by  `Pr(>|t|)` (also known as the p-value) which is the probability of achieving a |t| as large as or larger than the observed absolute t value if the null hypothesis (estimate = 0) was true. In short, it is the probability that there is no relationship between that feature and the predicted value (Ronald L. Wasserstein et al., 2016). `Estimate` shows the coefficient or weight gains by the responding features in this linear model. `Std.Error` is the standard error of the `estimate` value, which, can be used to calculate the Confidence interval. For example, the 95% confidence interval could be obtained from Estimate +- 1.96*Std.Error. `t value` is calculated from the estimates divided by their standard errors. To make the best use of this value, we need to look up the table of t distribution to learn the reject boundary. In this case, we could simply say the larger the magnitude of the t-value is, the less likely that the coefficient is 0.


```{r}
# investigate coefficients
summary(model_hs_17to37)
```



### <a id="potentialRelationshipTask"> Identify potential relationships between tasks </a>


To penalty the irrelevant features and ensure the comparison across the models, we plan to apply group lasso. However, before applying the multi-task learning method, we want to ensure there are potential relationships between tasks.

```{r}
motif_temperature_sensitive = c('UGUAHMNUA','TGTATAWT','ATATTC','TGTAAATA')
```

```{r}
names_temperature_condition = vector(mode="character", length=5)
names_temperature_condition[1] = "hs_15min_hs-1"
names_temperature_condition[2] = "hs_30min_hs-1"
names_temperature_condition[3] = "hs_40min_hs-1"
names_temperature_condition[4] = "hs_60min_hs-1"
names_temperature_condition[5] = "hs_80min_hs-1"
```

```{r, echo=FALSE, fig.width=10, fig.height=7}

# compute correlation coefficient
motif_overview <- as.data.frame(
  cor(fullTable_Gasch[names_motifs_valid],fullTable_Gasch[names_temperature_condition], use = "na.or.complete"))

# plot motifs with high correlation coefficient
ggplot(data = melt(setDT(as.data.frame(motif_overview[motif_temperature_sensitive,names_temperature_condition]), keep.rownames = TRUE), "rn"),
       aes(x=variable,y=value,group = rn)) + 
  geom_line(aes(colour=rn),size = 2) + 
  ylim(-0.3,0.1) + 
  labs(x = "after heat shock", y = "correlation coefficient") +
  scale_x_discrete(labels=c("hs_15min_hs-1" = "15min", "hs_30min_hs-1" = "30min","hs_40min_hs-1" = "40min","hs_60min_hs-1" = "60min","hs_80min_hs-1" = "80min")) + 
  theme(text = element_text(size=24))

```





```{r}
# pick a group of temperature condition
names_temperature_condition = vector(mode="character", length=3)
names_temperature_condition[1] = "29C(1M_sorbitol)~33C(1M_sorbitol)_05min"
names_temperature_condition[2] = "29C(1M_sorbitol)~33C(1M_sorbitol)_15min"
names_temperature_condition[3] = "29C(1M_sorbitol)~33C(1M_sorbitol)_30min"

```

```{r echo=FALSE, fig.width=10, fig.height=7}

# compute correlation coefficient
motif_overview_steady_temperature <- as.data.frame(
  cor(fullTable_Gasch[names_motifs_valid],fullTable_Gasch[names_temperature_condition], use = "na.or.complete"))

ggplot(data = melt(setDT(as.data.frame(motif_overview_steady_temperature[motif_temperature_sensitive,names_temperature_condition]), keep.rownames = TRUE), "rn"),
       aes(x=variable,y=value,group = rn)) + geom_line(aes(colour=rn),size = 2) + ylim(-0.25,0.1) + 
  labs(x = "after heat shock with sorbitol", y = "correlation coefficient")+
  scale_x_discrete(labels=c("29C(1M_sorbitol)~33C(1M_sorbitol)_05min" = "5min", "29C(1M_sorbitol)~33C(1M_sorbitol)_15min" = "15min","29C(1M_sorbitol)~33C(1M_sorbitol)_30min" = "30min")) + 
  theme(text = element_text(size=24))
```



```{r}
names_temperature_condition = vector(mode="character", length=5)
names_temperature_condition[1] = "hs_37to25_15min"
names_temperature_condition[2] = "hs_37to25_30min"
names_temperature_condition[3] = "hs_37to25_45min"
names_temperature_condition[4] = "hs_37to25_60min"
names_temperature_condition[5] = "hs_37to25_90min"
```


```{r, echo=FALSE, fig.width=10, fig.height=7}

# compute correlation coefficient
motif_overview <- as.data.frame(
  cor(fullTable_Gasch[names_motifs_valid],fullTable_Gasch[names_temperature_condition], use = "na.or.complete"))

## plot motifs with high correlation coefficient
ggplot(data = melt(setDT(as.data.frame(motif_overview[motif_temperature_sensitive,names_temperature_condition]), keep.rownames = TRUE), "rn"),
       aes(x=variable,y=value,group = rn)) + geom_line(aes(colour=rn),size=2) + ylim(-0.1,0.2) + 
  labs(x = "after hypothermia from 37C to 25C", y = "correlation coefficient")+
  scale_x_discrete(labels=c("hs_37to25_15min" = "15min", "hs_37to25_30min" = "30min","hs_37to25_45min" = "45min","hs_37to25_60min" = "60min","hs_37to25_90min" = "90min")) + 
  theme(text = element_text(size=24))


```



# Part 2: apply group lasso

### introduction

To investigate and quantify how the cis-regulatory element affects the gene regulation, we built a series of linear models where each model takes the frequencies of cis-regulatory elements as input and predicts how the gene expression level under certain environmental stress. Their coefficient can be used to estimate the regulatory effect of both a single cis-regulatory element or all the cis-regulatory as a group. For example, if an element is given a relatively large coefficient in a model which predicts the change of expression level under certain environmental stress, we can say the element play a relatively important role in the regulation under that environmental stress. On the other hand, the bias of the model can be considered as the expected gene expression level change of a gene with no cis-regulatory element we considered in the model. In other words, the bias indicates the expression level change that cannot be explained by the model and can be used to estimate the proportion of the efforts on regulation these cis-regulatory elements make. 

At this stage, our aim is to apply group lasso as a multi-task learning method to training all the models together which allows the comparison across each model and ensures their generalization. The L2 penalty term can filter out most of the irrelevant factors by penalizing their coefficient towards zero. 

The penalty on the coefficient vector for variable j is:
$$
(1-\alpha)/2||\beta_j||_2^2+\lambda||\beta_j||_2.
$$


### <a id="distributionMissingValue"> distribution of missing value </a>
Above all the expression level data, around 3% of them are missing value, Where most of the genes (94.8%) have a relatively complete expression levels' data (90%) while 41 genes (0.7%) have missing valves under more than quarter of environmental stresses.


| number of genes | missing value (n) |
| --------------- | ----------------- |
| 755 (12.3%)     | 0                 |
| 4372 (71.1%)    | 0 < n < 9 (5%)    |
| 701 (11.4%)     | 8 < n < 18 (10%)  |
| 283 (4.6%)      | 17 < n < 44 (25%) |
| 41 (0.7%)       | 43 < n < 99 (58%) |


```{r include=FALSE}
sum(is.na(expressionLevel_Gasch[4:176])) #number of missing values
sum(is.na(expressionLevel_Gasch[4:176]))/(173*6152) #ratio of missing value

na_count_sum = rowSums(is.na(expressionLevel_Gasch[4:176]))

max(na_count_sum)
length(na_count_sum[na_count_sum > 0 & na_count_sum < 9])
length(na_count_sum[na_count_sum > 8 & na_count_sum < 18])
length(na_count_sum[na_count_sum > 17 & na_count_sum < 44])
length(na_count_sum[na_count_sum > 43 & na_count_sum <99])
```

The 41 genes with missing values larger than 43 and smaller than 99
```{r}
names_genes = expressionLevel_Gasch$geneName
names_genes[na_count_sum > 43 & na_count_sum <99]
```



```{r echo=FALSE}
na_count_sum = rowSums(is.na(expressionLevel_Gasch[4:176]))
hist(na_count_sum, breaks = c(0,9,18,44,100), xlab="amount of missing value",ylab = "density of genes", main = 'histogram of missing value (genes)')
```

On the other hand, the distribution of missing value by 173 environmental stress indicates that there are 14 environmental stress that have a relatively higher missing value ratio (larger than 10% but smaller than 23%)

| number of environmental stresses | missing value (n)    |
| -------------------------------- | -------------------- |
| 0                                | 0                    |
| 55 (31.8%)                       | 0 < n < 62 (1%)      |
| 97 (56.1%)                       | 61 < n < 308 (5%)    |
| 7 (4.0%)                         | 307 < n < 616 (10%)  |
| 14 (8.1%)                        | 615 < n < 1385 (23%) |


```{r include=FALSE}
na_count_sum = colSums(is.na(expressionLevel_Gasch[4:176]))

max(na_count_sum)
length(na_count_sum[na_count_sum = 0])
length(na_count_sum[na_count_sum > 0 & na_count_sum < 62])
length(na_count_sum[na_count_sum > 61 & na_count_sum < 308])
length(na_count_sum[na_count_sum > 307 & na_count_sum < 616])
length(na_count_sum[na_count_sum > 615 & na_count_sum <1385])
```

```{r echo=FALSE}
hist(na_count_sum, breaks = c(0,62,308,616,1385), xlab="amount of missing value",ylab = "density of environmental stresses", main = 'histogram of missing value (environmental stresses)')
```

the 14 environmental stresses with missing value ratio larger than 10% are listed here
```{r}
na_count_sum[na_count_sum>315]
```


### <a id="filterGene"> filter out gene with high value-missing ratio </a>
The gene with high missing value could be caused by low abundance of mRNA in the cell which means there could be large errors for the measurements on these gene. It is better to remove them first.
```{r}
na_count_sum = rowSums(is.na(expressionLevel_Gasch[4:176]))
expressionLevel_Gasch_filtered = expressionLevel_Gasch[na_count_sum<18,]
```



### <a id="imputation"> fill missing data by imputation </a>
Applying imputation to estimate the missing values should be a much better way rather than simply ignore the missing values or replacing them by mean or 0 since it reduce the bias. Olga Troyanskaya et al.(2001) suggested that weighted K-nearest neighbors (KNNimpute) could be another sensitive method to deal with the missing value.

According to their article, when we consider gene A that has one missing value under environmental stress X, we could look for how the expression level of gene A change in other environmental stress Y and looking for k other genes B that show similar behavior as gene A. Then we fill the missing value by the weighted average of genes B. The contribution of each gene is weighted by similarity of its expression to that of gene A. 

we can estimate the performance of imputation by randomly knocking out 0.1% of non-NA and check the mean square error between estimation and actual value.
```{r include=FALSE}

k_value_validation_df = data.frame(matrix(ncol = 2, nrow = 0))

k_list = c(2,5,8,11,14,17,20,23,27,30)
size_test = 1000

for(k in k_list){
  for(randomSeed in 362136666:362136675){
    set.seed(randomSeed)
    
    
    row_numbers = c()
    column_numbers = c()
    
    matrix = as.matrix(expressionLevel_Gasch_filtered[4:length(expressionLevel_Gasch_filtered)])
    matrix_complete = matrix
    
    set.seed(randomSeed)
    row_random = sample(1:dim(matrix)[1],size_test*2,replace = TRUE)
    column_random = sample(1:dim(matrix)[2],size_test*2,replace = TRUE)
    
    
    i = 1
    j = 1
    while (i <= round(size_test*2) & j <= size_test) {
      if(!is.na(matrix[row_random[i],column_random[i]])){
        row_numbers = c(row_numbers,row_random[i])
        column_numbers = c(column_numbers,column_random[i])
        matrix[row_random[i],column_random[i]] = NA
        j = j + 1
      }
      i = i + 1
    }
    
    
    expressionLevel_impute_knn = (impute.knn(matrix ,k = k, rowmax = 0.5, colmax = 0.8, maxp = 7000, rng.seed=362436069))$data
    
    i = 1
    se = 0
    while (i < j) {
      se = se + (as.double(matrix_complete[row_numbers[i],column_numbers[i]]) - as.double(expressionLevel_impute_knn[row_numbers[i],column_numbers[i]]))^2
      i = i + 1
    }
    
    k_value_validation_df = rbind(k_value_validation_df, c(k,se/j))
    print(paste("k = ",k," mse = ",se/j))
  }
}


colnames(k_value_validation_df) = c("k","mse")
k_value_validation_df$k = as.integer(k_value_validation_df$k)

k_value_validation_ds <- do.call(rbind, lapply(split(k_value_validation_df, k_value_validation_df$k), function(d) {
  data.frame(mean = mean(d$mse), sd = sd(d$mse), k = d$k)
}))

```

```{r echo=FALSE}
ggplot() +
  geom_point(data = k_value_validation_df, aes(k, mse)) +
  geom_point(data = k_value_validation_ds, aes(k, mean), colour = 'red', size = 3) +
  geom_line(data = k_value_validation_ds, aes(k,mean), size = 1, colours = 'blue') +
  geom_errorbar(
    data = k_value_validation_ds,
    aes(k, mean, ymin = mean - sd, ymax = mean + sd),
    colour = 'red',
    width = 0.4
  )+
  theme(axis.text=element_text(size=16),axis.title=element_text(size=16,face="bold"))
```


an optimal value for k should sit between 5 and 20. In this case, we pick k = 11 for our imputation as a conserved and high-performance hyperparameter.
```{r echo=FALSE}
expressionLevel_impute_knn = (impute.knn(as.matrix(expressionLevel_Gasch_filtered[4:length(expressionLevel_Gasch_filtered)]) ,k = 11, rowmax = 0.5, colmax = 0.8, maxp = 7000, rng.seed=362436069))$data

expressionLevel_impute_knn = merge(expressionLevel_Gasch_filtered[1:3],expressionLevel_impute_knn, by = 0, sort = FALSE)
expressionLevel_impute_knn$Row.names <- NULL

fullTable_Gasch_impute_knn <- merge(expressionLevel_impute_knn,ref_motifs,by = "geneName")
```


### <a id="replaceZero"> baseline performance: simply replace missing value with 0 </a>
To estimate of the performance, we randomly knock out 0.1% of non-NA and check the mean square error.
```{r include=FALSE}
baseline_df = data.frame(matrix(ncol = 1, nrow = 0))

for(randomSeed in 362136666:362136675){
  size_test = 1000
  row_numbers = c()
  column_numbers = c()
  
  matrix = as.matrix(expressionLevel_Gasch_filtered[4:length(expressionLevel_Gasch_filtered)])
  
  set.seed(randomSeed)
  row_random = sample(1:dim(matrix)[1],size_test*2,replace = TRUE)
  column_random = sample(1:dim(matrix)[2],size_test*2,replace = TRUE)
  
  i = 1
  j = 1
  while (i <= round(size_test*2) & j <= size_test) {
    if(!is.na(matrix[row_random[i],column_random[i]])){
      row_numbers = c(row_numbers,row_random[i])
      column_numbers = c(column_numbers,column_random[i])
      j = j + 1
    }
    i = i + 1
  }
  
  
  se = 0
  for (i in 1:(j-1)) {
    se = se + (as.double(matrix[row_numbers[i],column_numbers[i]]))^2
  }
  
  baseline_df = rbind(baseline_df, c(se/j))
  print(paste("estimate mse = ",se/j))
  
}

colnames(baseline_df) = c("mse")

```

```{r echo=FALSE}
baseline_ds = data.frame(matrix(ncol = 2, nrow = 0))
baseline_ds = rbind(baseline_ds, c(mean(baseline_df$mse),sd(baseline_df$mse)))
colnames(baseline_ds) = c("mean","sd")

```



```{r echo=FALSE}
ggplot() +
  geom_point(data = baseline_df, aes("NA to zero", mse)) +
  geom_point(data = k_value_validation_df[k_value_validation_df$k == 11,], aes("kNN imputation (k=11)",mse)) +
  geom_point(data = baseline_ds, aes("NA to zero", mean), colour = 'red', size = 3) +
  geom_point(data = k_value_validation_ds[k_value_validation_ds$k == 11,], aes("kNN imputation (k=11)", mean), colour = 'red', size = 3) +
  geom_errorbar(
    data = baseline_ds,
    aes("NA to zero", mean, ymin = mean - sd, ymax = mean + sd),
    colour = 'red',
    width = 0.2
  ) + 
  geom_errorbar(
    data = k_value_validation_ds[k_value_validation_ds$k == 11,],
    aes("kNN imputation (k=11)", mean, ymin = mean - sd, ymax = mean + sd),
    colour = 'red',
    width = 0.2
  ) +
  theme(axis.text=element_text(size=16),axis.title=element_text(size=16,face="bold")) +
  labs(x = "")+
  ylim(0,0.8)

```


### consider motifs with non-zero frequency

```{r}
motifs_count_sum <- colSums(fullTable_Gasch[names_motifs_all],na.rm=TRUE)
remove_list = NULL

for (i in names(motifs_count_sum)){
  if (motifs_count_sum[[i]] == 0){
    remove_list <- c(remove_list,i)
  }
}

names_motifs_valid <- names_motifs_all[!names_motifs_all %in% remove_list]
```

### <a id="crossValidation"> choose lambda from 10-fold cross validation </a>
We need to set the hyperparameter lambda to control the effect of penalization. A common approch to this is by cross validation.
```{r echo=FALSE}
x = as.matrix(fullTable_Gasch_impute_knn[names_motifs_valid])
y = as.matrix(fullTable_Gasch_impute_knn[names_environmental_stress])

cv_models_all = cv.glmnet(x, y, family = "mgaussian")
```

```{r}
plot(cv_models_all)
```
`lambda.min` is the value of lambda that gives minimum cvm; `lambda.1se` is the largest value of lambda such that error is within 1 standard error of the minimum; The confidence intervals represent error estimates for the loss metric (red dots). They're computed using cross validation. The vertical dashed lines show the locations of λmin and λ1se. The numbers across the top are the number of nonzero coefficient estimates. The error is accumulated, and the average error and standard deviation over the folds is computed. 

### <a id="trainingModels"> training model with selected lambda </a>
training model with λ = `lambda.min` results in a model with highest expected performancec while training model with λ = `lambda.1se` results in a more conservative model with fewer non-zero regression coefficients.
```{r}
models_all_minLambda = glmnet(x, y, family = "mgaussian", lambda = cv_models_all$lambda.min)
models_all_1seLambda = glmnet(x, y, family = "mgaussian", lambda = cv_models_all$lambda.1se)

paste("lambda.min =",cv_models_all$lambda.min)
paste("lambda.1se =",cv_models_all$lambda.1se)
```


### the penalize effect with λ = lambda.1se is much stronger than that with λ = lambda.min
We summary coefficients from all the models together to compare the penalized effect of models with different λ values. The model with λ = lambda.1se penalizes more than 90% of coefficients to 0 while the model with λ = lambda.min keep more than half of its coefficients non-zero.

```{r echo=FALSE}
summary_lambda_coefficient = data.frame(matrix(ncol = 3, nrow = 0))

{
  count_nonzero_coefficient = 0
  for (condition in names_environmental_stress) {
    count_nonzero_coefficient = count_nonzero_coefficient + models_all_minLambda$beta[[condition]]@p[2]
  }
  
  count_all_coefficient = length(names_environmental_stress)*length(names_motifs_valid)
}

summary_lambda_coefficient = rbind(summary_lambda_coefficient, data.frame(
    lambda = "min",
    coefficient = "non-zero",
    percentage = count_nonzero_coefficient/count_all_coefficient
  ))
summary_lambda_coefficient = rbind(summary_lambda_coefficient, data.frame(
    lambda = "min",
    coefficient = "zero",
    percentage = (1 - count_nonzero_coefficient/count_all_coefficient)
  ))


{
  count_nonzero_coefficient = 0
  for (condition in names_environmental_stress) {
    count_nonzero_coefficient = count_nonzero_coefficient + models_all_1seLambda$beta[[condition]]@p[2]
  }
  
  count_all_coefficient = length(names_environmental_stress)*length(names_motifs_valid)
}

summary_lambda_coefficient = rbind(summary_lambda_coefficient, data.frame(
    lambda = "1se",
    coefficient = "non-zero",
    percentage = count_nonzero_coefficient/count_all_coefficient
  ))
summary_lambda_coefficient = rbind(summary_lambda_coefficient, data.frame(
    lambda = "1se",
    coefficient = "zero",
    percentage = (1 - count_nonzero_coefficient/count_all_coefficient)
  ))
```


```{r echo=FALSE}
ggplot(data=summary_lambda_coefficient, aes(x=lambda, y=percentage, fill=coefficient), labdels = percentage) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=percentage), position=position_dodge(width=0.9), vjust=-0.25)+
  scale_fill_brewer(palette="Paired")+
  theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title = element_text(size = 14))+
  ylab("percentage of coefficient")
  
```

```{r echo=FALSE}
coefficients = NULL
for (condition in names_environmental_stress) {
  coefficients = c(coefficients,models_all_minLambda$beta[[condition]]@x)
}

hist(coefficients, breaks = c(-3,-2.5,-2,-1.5,-1,-0.5,-0.2,-0.1, -0.05,0,0.05,0.1,0.2,0.5,1,1.5), main = 'histgram of non-zero coefficient when λ = lambda.min')
```


```{r echo=FALSE}
coefficients = NULL
for (condition in names_environmental_stress) {
  coefficients = c(coefficients,models_all_1seLambda$beta[[condition]]@x)
}

hist(coefficients, breaks = c(-2.5,-2,-1.5,-1,-0.5,-0.2,-0.1, -0.05,0,0.05,0.1,0.2,0.5,1), main = 'histgram of non-zero coefficient when λ = lambda.1se')

```


### regulatory effect of motifs decrease as time pass in heat shock
Here we plot a graph to show how the coefficient given to each motif change across the timeline after heat shock. For most of the motifs, their coefficients increase with shortly delay and reach their peak at 15mins. Than they gradually shift to 0 as time past. An explanation of the 15mins delay is that the cis-regulatory elements could regulate the expression level by adjusting the stability of mRNA which may need some time to decay.
```{r include=FALSE}
{
  names_temperature_condition = vector(mode="character", length=7)
  names_temperature_condition[1] = "hs_05min_hs-1"
  names_temperature_condition[2] = "hs_10min_hs-1"
  names_temperature_condition[3] = "hs_15min_hs-1"
  names_temperature_condition[4] = "hs_30min_hs-1"
  names_temperature_condition[5] = "hs_40min_hs-1"
  names_temperature_condition[6] = "hs_60min_hs-1"
  names_temperature_condition[7] = "hs_80min_hs-1"
}

```

```{r fig.height=7, fig.width=9}
plot_models_line(models_all_minLambda, names_temperature_condition, 10)
```



# Part 3: analyze the regression coefficient
### <a id="environmentalGroup"> divide environmental condition into groups </a>
With the models from group lasso, we can carefully select the regression coefficient from different groups of environmental conditions and compare them. By calculating the sum and L2 norm of their coefficient under each group of environmental condition, we are able to compare how the regulatory effect of each motif differ in each environmental stress. 

```{r}
{
  names_heatshock_29to33_condition = vector(mode="character", length=3)
  names_heatshock_29to33_condition[1] = "hs_29to33_05min"
  names_heatshock_29to33_condition[2] = "hs_29to33_15min"
  names_heatshock_29to33_condition[3] = "hs_29to33_30min"
}

{
  names_heatshock_sorbital_condition = vector(mode="character", length=3)
  names_heatshock_sorbital_condition[1] = "29C(1M_sorbitol)~33C(1M_sorbitol)_05min"
  names_heatshock_sorbital_condition[2] = "29C(1M_sorbitol)~33C(1M_sorbitol)_15min"
  names_heatshock_sorbital_condition[3] = "29C(1M_sorbitol)~33C(1M_sorbitol)_30min"
} 

{
  names_hypothermia_condition = vector(mode="character", length=3)
  names_hypothermia_condition[1] = "hs_37to25_15min"
  names_hypothermia_condition[2] = "hs_37to25_30min"
  names_hypothermia_condition[3] = "hs_37to25_60min"
} 

{
  names_heatshock_25to37_condition = vector(mode="character", length=3)
  names_heatshock_25to37_condition[1] = "hs_15min_hs-1"
  names_heatshock_25to37_condition[2] = "hs_30min_hs-1"
  names_heatshock_25to37_condition[3] = "hs_60min_hs-1"
} 


```



```{r echo=FALSE}

summary_coefficient = data.frame(matrix(ncol = 5, nrow = 0))


coefficients = extract_coefficient(models_all_minLambda,names_environmental_stress)

for(motif in names_motifs_valid){
  coefficients_motif_specific = coefficients[coefficients$rn == motif,]$value
  summary_coefficient = rbind(summary_coefficient, data.frame(
    motif = motif,
    condition = "all",
    L0 = sum((coefficients_motif_specific) != 0),
    sum = sum(coefficients_motif_specific),
    L2 = sqrt(sum(coefficients_motif_specific^2))
  ))
}




coefficients = extract_coefficient(models_all_minLambda,names_heatshock_29to33_condition)

for(motif in names_motifs_valid){
  coefficients_motif_specific = coefficients[coefficients$rn == motif,]$value
  summary_coefficient = rbind(summary_coefficient, data.frame(
    motif = motif,
    condition = "heat shock from 29C to 33C",
    L0 = sum((coefficients_motif_specific) != 0),
    sum = sum(coefficients_motif_specific),
    L2 = sqrt(sum(coefficients_motif_specific^2))
  ))
}


coefficients = extract_coefficient(models_all_minLambda,names_heatshock_sorbital_condition)

for(motif in names_motifs_valid){
  coefficients_motif_specific = coefficients[coefficients$rn == motif,]$value
  summary_coefficient = rbind(summary_coefficient, data.frame(
    motif = motif,
    condition = "heat shock with sorbitol",
    L0 = sum((coefficients_motif_specific) != 0),
    sum = sum(coefficients_motif_specific),
    L2 = sqrt(sum(coefficients_motif_specific^2))
  ))
}


coefficients = extract_coefficient(models_all_minLambda,names_hypothermia_condition)

for(motif in names_motifs_valid){
  coefficients_motif_specific = coefficients[coefficients$rn == motif,]$value
  summary_coefficient = rbind(summary_coefficient, data.frame(
    motif = motif,
    condition = "hypothermia from 37C to 25C",
    L0 = sum((coefficients_motif_specific) != 0),
    sum = sum(coefficients_motif_specific),
    L2 = sqrt(sum(coefficients_motif_specific^2))
  ))
}




coefficients = extract_coefficient(models_all_minLambda,names_heatshock_25to37_condition)

for(motif in names_motifs_valid){
  coefficients_motif_specific = coefficients[coefficients$rn == motif,]$value
  summary_coefficient = rbind(summary_coefficient, data.frame(
    motif = motif,
    condition = "heat shock from 25C to 37C",
    L0 = sum((coefficients_motif_specific) != 0),
    sum = sum(coefficients_motif_specific),
    L2 = sqrt(sum(coefficients_motif_specific^2))
  ))
}


```



### <a id = "L2Allcondition"> L2 norm of the non-zero regression coefficient from significant motif under all condition </a>
The following graph shows the L2 norm of the regression coefficient of some significant motif under all environmental conditions. The rank of each motif shows how significant a motif is in the environmental conditions we considered. However, since the models we fitted here only considered some typical environmental stress on yeast and is very unbalanced in the type of condition (about 40 model is temperature relevant), we couldn't say the high-rank motif shown here is significant under general environmental stress.

```{r echo=FALSE, fig.height=8, fig.width=14}
summary_coefficient_temp = summary_coefficient[summary_coefficient$condition == "all",]
summary_coefficient_temp = summary_coefficient_temp[order(-summary_coefficient_temp$L2),]


ggplot(data=head(summary_coefficient_temp,31), aes(x=reorder(motif,-L2), y=L2, fill=condition)) +
  geom_bar(stat="identity", position=position_dodge()) +
  theme(axis.text.x = element_text(size = 16, angle = 70, hjust = 1),
        axis.text.y = element_text(size = 16),
        legend.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        title = element_text(size = 14)) + 
  scale_x_discrete(name ="Motif") + 
  ggtitle("L2 of the non-zero regression coefficient from significant motif under all condition")
```

### <a id = "heatShockHypothermia"> compare L2 nore and sum of the non-zero regression coefficient from significant motif under heat shock and hypothermia </a>
the regulatory effect of each motif under hypothermia is much smaller than that under heat shock. This could probably reflect the trigger of environmental stress response (ESR) mention by Gasch et al. (2000): "the ESR is not initiated in response to all environmental changes and that the large, transient changes in expression that are characteristic of the ESR are only seen when this response is initiated and not in the reciprocal response to diminished environmental stress."

```{r echo=FALSE, fig.height=8, fig.width=14}
summary_coefficient_temp = summary_coefficient[summary_coefficient$condition == "heat shock from 25C to 37C" | summary_coefficient$condition == "hypothermia from 37C to 25C",]
summary_coefficient_temp = summary_coefficient_temp[order(-summary_coefficient_temp$L2),]
summary_coefficient_temp = summary_coefficient_temp[summary_coefficient_temp$motif %in% unique(head(summary_coefficient_temp,30)$motif),]

ggplot(data=summary_coefficient_temp, aes(x=reorder(motif,-L2), y=L2, fill=condition)) +
  geom_bar(stat="identity", position=position_dodge()) +
  theme(axis.text.x = element_text(size = 16, angle = 70, hjust = 1),
        axis.text.y = element_text(size = 16),
        legend.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        title = element_text(size = 14)) + 
  scale_x_discrete(name ="Motif") + 
  ggtitle("L2 of the non-zero regression coefficient of significant motifs under heat shock and hypothermia after 15, 30 and 60 min")
```

```{r echo=FALSE, fig.height=8, fig.width=14}
summary_coefficient_temp = summary_coefficient[summary_coefficient$condition == "heat shock from 25C to 37C" | summary_coefficient$condition == "hypothermia from 37C to 25C",]
summary_coefficient_temp = summary_coefficient_temp[order(-summary_coefficient_temp$L2),]
summary_coefficient_temp = summary_coefficient_temp[summary_coefficient_temp$motif %in% unique(head(summary_coefficient_temp,30)$motif),]


ggplot(data=summary_coefficient_temp, aes(x=reorder(motif,-L2), y=sum, fill=condition)) +
  geom_bar(stat="identity", position=position_dodge()) +
  theme(axis.text.x = element_text(size = 16, angle = 70, hjust = 1),
        axis.text.y = element_text(size = 16),
        legend.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        title = element_text(size = 14)) + 
  scale_x_discrete(name ="Motif") + 
  ggtitle("Sum of the non-zero regression coefficient of significant motifs under heat shock and hypothermia after 15, 30 and 60 min")
```


### <a id="heatShocksorbitol"> compare L2 norm and sum of the non-zero regression coefficient from significant motif under heat shock, heat shock with sorbitol </a>
Although most of the regression coefficients are similar in both heat shock with and without sorbitol, there are some motifs show a relatively different regulatory effect on gene expression with sorbitol. Check the second graph `Sum of the non-zero regression coefficient of significant motifs under heat shock with and without sorbitol after 5, 15 and 30 min`, it is easy to see `TGAGGCTA` shows a much stronger regulatory effect on gene expression when there is sorbitol while `UKWCGRGGN` and `GTAGTATTT` acting in an opposite way, a much weaker regulatory effect under heat shock with sorbitol.


```{r echo=FALSE, fig.height=8, fig.width=14}
summary_coefficient_temp = summary_coefficient[summary_coefficient$condition == "heat shock from 29C to 33C" | summary_coefficient$condition == "heat shock with sorbitol",]
summary_coefficient_temp = summary_coefficient_temp[order(-summary_coefficient_temp$L2),]
summary_coefficient_temp = summary_coefficient_temp[summary_coefficient_temp$motif %in% unique(head(summary_coefficient_temp,30)$motif),]



ggplot(data=summary_coefficient_temp, aes(x=reorder(motif,-L2), y=L2, fill=condition)) +
  geom_bar(stat="identity", position=position_dodge()) +
  theme(axis.text.x = element_text(size = 16, angle = 70, hjust = 1),
        axis.text.y = element_text(size = 16),
        legend.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        title = element_text(size = 14)) + 
  scale_x_discrete(name ="Motif") + 
  ggtitle("L2 of the non-zero regression coefficient of significant motifs under heat shock with and without sorbitol after 5, 15 and 30 min")
```



```{r echo=FALSE, fig.height=8, fig.width=14}
summary_coefficient_temp = summary_coefficient[summary_coefficient$condition == "heat shock from 29C to 33C" | summary_coefficient$condition == "heat shock with sorbitol",]
summary_coefficient_temp = summary_coefficient_temp[order(-summary_coefficient_temp$L2),]
summary_coefficient_temp = summary_coefficient_temp[summary_coefficient_temp$motif %in% unique(head(summary_coefficient_temp,30)$motif),]


ggplot(data=summary_coefficient_temp, aes(x=reorder(motif,-L2), y=sum, fill=condition)) +
  geom_bar(stat="identity", position=position_dodge()) +
  theme(axis.text.x = element_text(size = 16, angle = 70, hjust = 1),
        axis.text.y = element_text(size = 16),
        legend.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        title = element_text(size = 14)) + 
  scale_x_discrete(name ="Motif") + 
  ggtitle("Sum of the non-zero regression coefficient of significant motifs under heat shock with and without sorbitol after 5, 15 and 30 min")
```




