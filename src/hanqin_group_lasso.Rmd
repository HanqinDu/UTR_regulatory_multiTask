---
title: "hanqin_group_lasso"
author: "Hanqin Du"
date: "2020/1/11"
output: html_document
---


```{r set work space for r, eval=FALSE, echo=FALSE}
par(mfrow=c(1,1))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
```

## Up date aims
***

[^structure]: Objectives should be more specific actions that you expect to carry out (e.g. simulate, test, compare). At the end of the project it should be possible to assess which objectives have been met.

#### Quantify the effect of cis-regulatory elements under different environmental stress by fitting linear models with group lasso

To investigate and quantify how the cis-regulatory element affects the gene regulation, we built a series of linear models where each model takes the frequencies of cis-regulatory elements as input and predicts how the gene expression level under certain environmental stress. Their coefficient can be used to estimate the regulatory effect of both a single cis-regulatory element or all the cis-regulatory as a group. For example, if an element is given a relatively large coefficient in a model which predicts the change of expression level under certain environmental stress, we can say the element play a relatively important role in the regulation under that environmental stress. On the other hand, the bias of the model can be considered as the expected gene expression level change of a gene with no cis-regulatory element we considered in the model. In other words, the bias indicates the expression level change that cannot be explained by the model and can be used to estimate the proportion of the efforts on regulation these cis-regulatory elements make. 

At this stage, our aim is to apply group lasso as a multi-task learning method to training all the models together which allows the comparison across each model and ensures their generalization. The L2 penalty term can filter out most of the irrelevant factors by penalizing their coefficient close to zero. 

The penalty on the coefficient vector for variable j is:
$$
(1-\alpha)/2||\beta_j||_2^2+\lambda||\beta_j||_2.
$$


## set up
***

#### Load library
```{r load library, results='hide', message=FALSE, echo=FALSE}
library(data.table)
library(tidyverse)
library(lmodel2)
library(splitstackshape)
library(gridExtra)
library(glmnet)
```

#### Load function
```{r results='hide', message=FALSE, echo=FALSE}
strReverse <- function(x)
        sapply(lapply(strsplit(x, NULL), rev), paste, collapse="")
  
plot_labels = function(labels, ylim){
  plot(1:length(labels)[1], type = 'n', xlab="",ylab="coefficient",xaxt="n",xlim = c(0.5,length(labels)[1]+0.5), ylim = ylim)+
    axis(side=1,at=1:length(labels)[1],labels=labels) + abline(h=0, col="grey")
}

plot_points <- function(data, color){
  points(x = 1:length(data)[1],y = data,pch = 16,col = color)
}

plot_line <- function(data, color){
  lines(x = 1:length(data)[1], y = data, pch = 16, col = color)
}

range_coe <- function(beta_list){
  n = length(beta_list)
  minimum = 0
  maximum = 0
  for (i in (1:n)) {
    minimum = min(minimum, min(beta_list[[i]]))
    maximum = max(maximum, max(beta_list[[i]]))
  }
  return(c(minimum,maximum))
}

mask_characters <- function(c1,c2){
  n = length(c1)
  m = length(c2)
  output = c()
  for (i in 1:n) {
    for (j in 1:m) {
      if(c1[i] == c2[j]){
        output = append(output,i)
      }
    }
  }
  return(output)
}

```


## import data
***

#### Expression level change of 6152 distinct genes under 173 different environmental stresses from Gasch's study

In this project, we apply the data describes gene expression level in various environment condition from Gasch's study `Genomic Expression Programs in the Response of Yeast Cells to Environmental Changes`. To figure out how the expression level change, DNA microarrays were used.



#### 69 sequence motifs found on RNA untranslated region from 3 different studies

The 69 sequence motifs we use in this project is from 3 different studies:

53 of them come from the study of Shalgi et al (2005). The candidate motifs are derived by analyzing the exhaustively enumerating all k-mers(k = {8,9,10,11,12}) and looking for over-represented motifs with extreme half-life value. For the k-mers method, 515 significant k-mers are selected with ranksum test and clustered by ClustalW which resulted in 51 clusters of motifs. on the other hand, 2 more motifs are found by grouping genes with extreme half-life and ran Gibbs sampler.

14 of them come from the study of Hogan et al. (2008). Two related computational methods are applied to identify candidates for the binding sites of 40 out of the more than 500 known and predicted RBPs in S. cerevisiae: (1)“finding informative regulatory elements” (FIRE) and (2)“relative filtering by nucleotide enrichment” (REFINE). The previous one searches for motifs with informative patterns of enrichment and the other one identifies all hexamers that are significantly enriched in untranslated regions, filters out regions of target sequences that are relatively devoid of such hexamers, and then applies the “multiple expectation maximization for motif elicitation” (MEME) motif-finding algorithm. As a result, 14 motifs that are likely to be the binding sites of 16 RBP are found.

The rest 4 are from the study of Cheng (2017), four mRNA-stability related motifs in the 3′ UTR are found by De novo motif searching and their reliability and effect have been examined by linear mixed effect model, Fisher test P-value corrected with Benjamini–Hochberg, Wilcoxon rank-sum test and multivariate linear regression.


#### UTR sequence of 4388 genes from Sun et al. (2013)

UTR sequence of 4388 genes are obtained from Sun, M. et al. (2013) ‘Global analysis of Eukaryotic mRNA degradation reveals Xrn1-dependent buffering of transcript levels’. 



## Load Data
***
Load 69 published motifs (from Abhi's report) and 3'UTR sequences of 4388 different genes. Then, Load Gasch's gene-expression-level data which describes the relative gene expression level under 173 different environment conditions among 6152 genes.

```{r Load Data, echo=FALSE, warning=FALSE, message=FALSE}

#ref datasets for UTRs 
UTR_raw <- read_rds("../data/Sun_mutation_UTRs.rds")
  #Get sequences from UTR_raw in a separate vector
  UTR_3 <- UTR_raw$UTR3_seq

#Load Manually created motifs list into a vector
motifs_raw <- scan("../data/list_motifs.txt", character())
motifs_cheng = c("TGTAAATA", "TGCAT", "TTTTTTA", "ATATTC")


# load Gasch's data
expressionLevel_Gasch <- read_tsv("../data/Gasch2000_complete_dataset_rename.txt", 
                       locale = locale(decimal = ","))

# convert all the expression data to number
for (i in names(expressionLevel_Gasch)[3:176]) {
  expressionLevel_Gasch[[i]] <- as.double(as.character(expressionLevel_Gasch[[i]]))
}

```

#### Construct Motif Frequencies Matrix from 3'UTR Ref sequences
By converting all the motifs to regular expression, we are able to construct motifs frequency matrix which describes the frequency of 69 motifs among 4388 different genes.
```{r construct motif frequency, echo=FALSE}

#Dictionary for non-specific codes and converting U -> T
motifs <- motifs_raw %>% str_replace_all(c("U" = "T", "W" = "(A|T)", "S" = "(C|G)", "M" = "(A|C)", "K" = "(G|T)", "R" = "(A|G)", "Y" = "(C|T)", "B" = "(C|G|T)", "D" = "(A|G|T)", "H" = "(A|C|T)", "V" = "(A|C|G)", "N" = "(A|C|G|T)"))

#Initate ref tibble and store gene names
ref_motifs <- tibble(geneName = UTR_raw$genename)


#Search and add frequency of each c(motif) as a column in ref dataset
for (i in 1:length(motifs)){
  ref_motifs <- mutate(.data = ref_motifs,!!motifs_raw[i] := str_count(UTR_3, motifs[i]))
}

#Search and add frequency of each c(motif) as a column in ref dataset
for (i in 1:length(motifs)){
  ref_motifs <- mutate(.data = ref_motifs,!!motifs_raw[i] := str_count(UTR_3, motifs[i]))
}

names_motifs_all = names(ref_motifs)[2:length(ref_motifs)]
names_environmental_stress = names(expressionLevel_Gasch)[4:length(expressionLevel_Gasch)]
```




#### Merge motif frequency matrix with Gasch's data
Finally, we inner join the motif frequency matrix with Gasch's data and get the data frame we are going to explore. Each row represented data from one of the 4284 genes (since we have carried out inner join, only the genes shown in both tables are kept). There are 245 columns in total. 3 of them describe the basic information (short and formal name) of the gene represented by the row. 173 of them show how the gene expression level change under the certain environment condition and the other 69 of them respect the frequency of the 69 published motifs on the 3’UTR.
```{r merge motifs frequency with gasch data, echo=FALSE}

# merge motifs
fullTable_Gasch <- merge(expressionLevel_Gasch,ref_motifs,by = "geneName")

# convert type of motifs frequency to factor for violin plotting
fullTable_Gasch_double = fullTable_Gasch
for(i in names_motifs_all){
    fullTable_Gasch_double[[i]] <- as.double(as.character(fullTable_Gasch_double[[i]]))
}

```


#### Remove motifs with frequency 0
```{r echo=FALSE}
motifs_count_sum <- colSums(fullTable_Gasch[names_motifs_all],na.rm=TRUE)
remove_list = NULL

for (i in names(motifs_count_sum)){
  if (motifs_count_sum[[i]] == 0){
    remove_list <- c(remove_list,i)
  }
}

names_motifs_valid <- names_motifs_all[!names_motifs_all %in% remove_list]
```



## investigate the missing value
***

#### 3% of the expression level data microarray are missing
We noticed that, above all the expression level data, around 3% of them are missing value, Where most of the genes (94.8%) have a relatively complete expression levels' data (90%) while 41 genes (0.7%) have missing valves under more than quarter of environmental stresses.

| number of genes | missing value (n) |
| --------------- | ----------------- |
| 755 (12.3%)     | 0                 |
| 5073 (82.5%)    | 0 < n < 18        |
| 283 (4.6%)      | 17 < n < 44       |
| 41 (0.7%)       | 43 < n < 100      |


```{r eval=FALSE, echo=FALSE}
sum(is.na(expressionLevel_Gasch[4:176])) #number of missing values
sum(is.na(expressionLevel_Gasch[4:176]))/(173*6152) #ratio of missing value

na_count_sum = rowSums(is.na(expressionLevel_Gasch[4:176]))

length(na_count_sum[na_count_sum > 0 & na_count_sum < 18])
length(na_count_sum[na_count_sum > 17 & na_count_sum < 44])
length(na_count_sum[na_count_sum > 43 & na_count_sum < 100])
```
```{r echo=FALSE}
na_count_sum = rowSums(is.na(expressionLevel_Gasch[4:176]))
hist(na_count_sum, breaks = c(0,1,2,5,10,20,30,50,70,100), main = 'histgram of percentage of missing value')
```




#### (1) replace missing value with 0
As one of the easiest way to deal with the missing values, we could simply replace them by 0
```{r}
fullTable_Gasch_na2zero = fullTable_Gasch
fullTable_Gasch_na2zero[is.na(fullTable_Gasch_na2zero)] <- 0.0
```


#### (2) carry out inputation to replace missing data with substituted values
Applying imputation to estimate the missing values should be a much better way rather than simply ignore the missing values or replacing them by mean or 0 since it reduce the bias. Olga Troyanskaya et al. suggest in their article `Missing value estimation methods for DNA microarrays` that weighted K-nearest neighbors (KNNimpute) could be another sensitive method to deal with the missing value

> We show that KNNimpute appears to provide a more robust and sensitive method for missing value estimation than SVDimpute, and both SVDimpute and KNNimpute surpass the commonly used row average method (as well as filling missing values with zeros).

According to Olga Troyanskaya et al., when we consider gene A that has one missing value under environmental stress X, we could look for how the expression level of gene A change in other environmental stress Y and looking for k other genes B that show similar behavior as gene A. Then we fill the missing value by the weighted average of genes B. The contribution of each gene is weighted by similarity of its expression to that of gene A. 

```{r}
# unimplemented
```



## glmnet group lasso notes
***


#### basic idea about glmnet group lasso

reference:

[^rdocumentation]: https://www.rdocumentation.org/packages/glmnet/versions/3.0-2/topics/glmnet
[^glmnet]: https://cran.r-project.org/web/packages/glmnet/glmnet.pdf
[^alpha]: https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html
[^A SPARSE-GROUP LASSO]: https://web.stanford.edu/~hastie/Papers/SGLpaper.pdf
[^wiki]: https://en.wikipedia.org/wiki/Lasso_(statistics)#Group_lasso
[^lasso and ridge]: https://www.zhihu.com/question/38121173
[^lasso and ridge]: https://zhuanlan.zhihu.com/p/46999826
[^code example]: https://cosx.org/2016/10/data-mining-1-lasso/
[^ cv code example]: https://stats.stackexchange.com/questions/253963/how-to-interpret-cv-glmnet-plot


defination of p-norm
$$
||x||_p := (\sum ^n_{i=1}|x_i|^p)^{1\over p}
$$


Glmnet is a package that fits a generalized linear model via penalized maximum likelihood. The regularization path is computed for the lasso or elasticnet penalty at a grid of values for the regularization parameter lambda.

$$
\min_{\beta_0,\beta} \frac{1}{N} \sum_{i=1}^{N} w_i l(y_i,\beta_0+\beta^T x_i) + \lambda\left[(1-\alpha)||\beta||_2^2/2 + \alpha ||\beta||_1\right],
$$

Where l(y,η) is the negative log-likelihood contribution for observation i. Accroding to the introduction of glmnet, the penalty on the coefficient vector for variable j is
$$
(1-\alpha)/2||\beta_j||_2^2+\alpha||\beta_j||_1.
$$

Setting `family="mgaussian"` allows a multi-response gaussian model to be fit, using a "group -lasso" penalty on the coefficients for each variable.
Setting `type.multinomial="grouped"` allows the same penalty as `family="mgaussian"`, which is:
$$
(1-\alpha)/2||\beta_j||_2^2+\alpha||\beta_j||_2.
$$
when `alpha = 1` this is a group-lasso penalty, and otherwise it mixes with quadratic just like elasticnet. In group lasso, we summing all the penalty


#### compare L1 and L2

- L1 could have more than one optimal solution while L2 only has one
- L1 is more robust. no sensitive to extreme value
- L1 give more 0 to not important features (better for feature selection)
- L2 is easier to calculate


## multi-task learning on all 173 environmental stress
***

```{r}
names_condition = colnames(expressionLevel_Gasch, do.NULL = TRUE, prefix = "col")[4:176]

x = as.matrix(fullTable_Gasch_na2zero[names_motifs_valid])
y = as.matrix(fullTable_Gasch_na2zero[names_condition])

cv_models_all = cv.glmnet(x, y, family = "mgaussian")
```


#### pick lambda with 10-fold cross validation
`lambda.min` is the value of lambda that gives minimum cvm; `lambda.1se` is the largest value of lambda such that error is within 1 standard error of the minimum; The confidence intervals represent error estimates for the loss metric (red dots). They're computed using cross validation. The vertical dashed lines show the locations of λmin and λ1se. The numbers across the top are the number of nonzero coefficient estimates. The error is accumulated, and the average error and standard deviation over the folds is computed. 

```{r}
plot(cv_models_all)
```

#### training models with the lambda value that gives minimum loss. a majority of coefficients are very close to 0, the effect of penalty is significant.
Here we let alpha=1 as default to achieve a group-lasso penalty, and otherwise it mixes with quadratic just like elasticnet.
```{r echo=FALSE}
models_all = glmnet(x, y, family = "mgaussian", lambda = cv_models_all$lambda.min)
```


```{r}
coefficients = NULL
for (condition in names_condition) {
  coefficients = c(coefficients,models_all$beta[[condition]]@x)
}

hist(coefficients, breaks = c(-2.5,-2,-1.5,-1,-0.5,-0.2,-0.1,0,0.1,0.2,0.5,1), main = 'histgram of non-zero coefficient')

```

#### 28% of the coefficient are penalized to zero

```{r }
count_nonzero_coefficient = 0

for (condition in names_environmental_stress) {
  count_nonzero_coefficient = count_nonzero_coefficient + models_all$beta[[condition]]@p[2]
}

count_all_coefficient = length(names_environmental_stress)*length(names_motifs_valid)

1 - (count_nonzero_coefficient/count_all_coefficient)

```


#### coefficient shift to zero as the time after environmental stress increasing

```{r include=FALSE}
{
  names_temperature_condition = vector(mode="character", length=5)
  names_temperature_condition[1] = "hs_05min_hs-1"
  names_temperature_condition[2] = "hs_10min_hs-1"
  names_temperature_condition[3] = "hs_15min_hs-1"
  names_temperature_condition[4] = "hs_30min_hs-1"
  names_temperature_condition[5] = "hs_40min_hs-1"
  names_temperature_condition[6] = "hs_60min_hs-1"
  names_temperature_condition[7] = "hs_80min_hs-1"
}

{
  coefficients = NULL
  
  for (condition in names_temperature_condition) {
    column = numeric(models_all$beta[[condition]]@Dim[1])
    column[models_all$beta[[condition]]@i+1] = models_all$beta[[condition]]@x
    coefficients = cbind(coefficients,column)
  }
  coefficients = as.data.frame(coefficients)
  names(coefficients) = names_temperature_condition
  row.names(coefficients) = names_motifs_valid
  melt(setDT(coefficients, keep.rownames = TRUE), "rn")
}
```

```{r echo=FALSE, fig.height=10, fig.width=12}


ggplot(data = melt(setDT(coefficients[1:10], keep.rownames = TRUE), "rn"), aes(x=variable,y=value,group = rn)) + 
  geom_line(aes(colour=rn))

ggplot(data = melt(setDT(coefficients[11:20], keep.rownames = TRUE), "rn"), aes(x=variable,y=value,group = rn)) + 
  geom_line(aes(colour=rn))

ggplot(data = melt(setDT(coefficients[21:30], keep.rownames = TRUE), "rn"), aes(x=variable,y=value,group = rn)) + 
  geom_line(aes(colour=rn))

ggplot(data = melt(setDT(coefficients[31:40], keep.rownames = TRUE), "rn"), aes(x=variable,y=value,group = rn)) + 
  geom_line(aes(colour=rn))

ggplot(data = melt(setDT(coefficients[41:50], keep.rownames = TRUE), "rn"), aes(x=variable,y=value,group = rn)) + 
  geom_line(aes(colour=rn))


```


#### Analysis the Bias
The bias of each model shows the change of expression level that cannot be explained by these motifs
here we calculate the percentage of it against the mean of change in expression level to estimate how much of the regulation effect cannot be expalined by the model. The estimation is base on many assumptions and could be very ambiguous. 

$$
bias\over mean( expression\ level)
$$


```{r} 
models_all$a0/colMeans(fullTable_Gasch_double[names_condition], na.rm = TRUE)
```


#### compare coefficient under oopposite environmental stress
```{r echo=FALSE, fig.height=10, fig.width=12}
{
  plot_labels(names_motifs_valid, range_coe(models_all$beta))
  plot_points(models_all$beta$`hs_15min_hs-1`,'red')
  plot_points(models_all$beta$`hs_37to25_15min`,'blue')
  legend('bottomleft', legend=c('heat shock','cool down'), col=c('red','blue'), lty = 1)
}

{
  plot_labels(names_motifs_valid, range_coe(models_all$beta))
  plot_line(models_all$beta$`hs_15min_hs-1`,'red')
  plot_line(models_all$beta$`hs_37to25_15min`,'blue')
  legend('bottomleft', legend=c('heat shock','cool down'), col=c('red','blue'), lty = 1)
}

```



#### compare coefficient of heat shock with and without sorbital - 5min
check if the `additional effect` mension by Gasch is shown in the models. The effect is obvious at first and decrease in 30 mins
```{r echo=FALSE, fig.height=10, fig.width=12}

{
  plot_labels(names_motifs_valid, range_coe(models_all$beta))
  plot_line(models_all$beta$`hs_29to33_05min`,'red')
  plot_line(models_all$beta$`29C(1M_sorbitol)~33C(1M_sorbitol)_05min`,'blue')
  plot_line(models_all$beta$`1M_sorbitol_05min`,'forestgreen')
  legend('bottomleft', legend=c('hs with sorbitol','hs without sorbitol','sorbitol without hs'), col=c('red','blue','forestgreen'), lty = 1)
}
```



#### compare coefficient of heat shock with and without sorbital - 15min
```{r echo=FALSE, fig.height=10, fig.width=12}

{
  plot_labels(names_motifs_valid, range_coe(models_all$beta))
  plot_line(models_all$beta$`hs_29to33_15min`,'red')
  plot_line(models_all$beta$`29C(1M_sorbitol)~33C(1M_sorbitol)_15min`,'blue')
  plot_line(models_all$beta$`1M_sorbitol_15min`,'forestgreen')
  legend('bottomleft', legend=c('hs','sorbitol','hs + sorbitol'), col=c('red','forestgreen','blue'), lty = 1)
}
```


#### compare coefficient of heat shock with and without sorbital - 30min
```{r echo=FALSE, fig.height=10, fig.width=12}

{
  plot_labels(names_motifs_valid, range_coe(models_all$beta))
  plot_line(models_all$beta$`hs_29to33_30min`,'red')
  plot_line(models_all$beta$`29C(1M_sorbitol)~33C(1M_sorbitol)_30min`,'blue')
  plot_line(models_all$beta$`1M_sorbitol_30min`,'forestgreen')
  legend('bottomleft', legend=c('hs','sorbitol','hs + sorbitol'), col=c('red','forestgreen','blue'), lty = 1)
}
```




markdown report: what learning from existing motifs
explain what the model tell us about these motifs
fitting model - use the model as the central part, indicate how to improve and learning from it
feature selection: which motifs make effort

