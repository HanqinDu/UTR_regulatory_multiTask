{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019MotifHonoursProject\n",
    "Code and resources compiled together as part of the Jan 2019 honours student project on predicting the effects of 3'UTR motifs\n",
    "\n",
    "Please make sure you have installed the R programming language, its exceptionally useful IDE Rstudio and the sanity saving version control software git. (Plus send me your github account usernames so I can add you as collaborators)\n",
    "\n",
    "https://www.r-project.org\n",
    "\n",
    "https://www.rstudio.com\n",
    "\n",
    "https://git-scm.com\n",
    "\n",
    "## Getting Started\n",
    "First off let us make sure git and Rstudio are correctly installed (and than we can talk about what they do!).\n",
    "\n",
    "Open a terminal and use the cd command to move to a suitable folder for all future honours project work (i.e. a place regularly backed up). Familiarity with the UNIX commandline is assumed, please see http://www.ee.surrey.ac.uk/Teaching/Unix/ for a tutorial otherwise.\n",
    "\n",
    "Towards the top right of this page is the clone or download button, click there and copy the URL.\n",
    "\n",
    "Type the code below with the copied URL inserted and enter.\n",
    "\n",
    "```bash\n",
    "git clone <repository url>\n",
    "```\n",
    "\n",
    "Hopefully the command will run smoothly and you can cd to the new 2019MotifHonoursProject folder on your local machine.\n",
    "\n",
    "If you have got this far git appears to be working correctly. Now lets try R and Rstudio! \n",
    "\n",
    "Open the babySteps.R file either via the terminal with the code below or however you choose to open Rstudio.\n",
    "\n",
    "```bash\n",
    "open -a Rstudio ./src/babySteps.R\n",
    "```\n",
    "Go to the code tab in Rstudio, then run region and run all. (If this works try looking into the keyboard shortcuts for running the code for future use).\n",
    "\n",
    "We can now relatively safely say R, Rstudio and git are running nicely.\n",
    "\n",
    "## Git and Rstudio\n",
    "\n",
    "Let's start with Rstudio.\n",
    "\n",
    "Rstudio is an example of an integrated development environment or IDE. You don't need it to program in R, you could in fact open notepad and type away without ever thinking about Rstudio. Unfortunately managing variables, debugging and package management would just be a massive pain. IDEs, ubiquitous to all programming languages in one form or another, contain a suite of tools which make progamming easier and believe me we already have plenty to think about.\n",
    "\n",
    "Git, on the other hand, is a piece of version control software. It is a log of all the changes made to a set of files since the last time git was ran. Regularly updating the git log will allow you to quickly return to a working version of your code when the inevitable bug appears (and highlight what has been changed). In addition, correct implimentation of modular progamming can take advantage of git's branching ability. Once a simple husk of your code is created you can produce separate branchs of the git log, each focused on different sections or extensions of the original model. Each branch can be worked on by different people, or the same person at different times. This ensures the original or master code cannot be accidentally broken by anyone at anytime because each branch has its own copy of the master file which is changed, the master file is never changed. Git's genius lies in the merging software it contains which allows for seamless integration of different branching archs once they reach completion. Finally, pair git with github (using an online repository rather than a local one) and you get a powerful tool encouraging open source programming, collaboration, regular backups and near-limitless distribution. Only after the painful discovery of a catastrophic programming error will the importance of git dawn on you!\n",
    "\n",
    "### Introductory Task\n",
    "\n",
    "Following [this](https://guides.github.com/activities/hello-world/) tutorial and using [this](https://www.atlassian.com/git/tutorials/atlassian-git-cheatsheet) git code cheatsheet\n",
    "\n",
    "1. Create a new branch for your local copy of this git repository, name it something like \\<yourname\\>GitTest\n",
    "2. Create a new R file, write a short program consisting of a function that will add two arguments together with an example of it being called\n",
    "3. Commit this new file to git and push it back to my online github repo\n",
    "4. Now merge your newly created branch with the master and push to your own github repo!\n",
    "\n",
    "Meanwhile, https://www.tutorialspoint.com/git/git_basic_concepts.htm will tell you more than you could ever want to know about git\n",
    "\n",
    "## Getting used to data manipulation and plotting\n",
    "\n",
    "To begin, make sure you have the following packages installed!\n",
    "```R\n",
    "install.packages(tidyverse)\n",
    "install.packages(ggplot2)\n",
    "```\n",
    "\n",
    "These two packages contain many of the fundamental functions of data manipulation. Unfortunately, data is normally poorly formated and some functions can be very specific about the structure of its arguments. tidyverse combines tonnes of useful ways of manipulating tables into different shapes, repeating functions over groups of elements and making your code more read friendly. Start to familiarise yourself with tidyverse by going through the [basic](https://ourcodingclub.github.io/2017/03/20/seecc.html) and [advanced](https://ourcodingclub.github.io/2018/03/06/tidyverse.html#tidyverse) tutorials on the UoE's very own [ourcodingclub](https://ourcodingclub.github.io/tutorials/) website.\n",
    "\n",
    "Another useful skill is to be able to plot informative, journal ready graphs, ggplot2 is a great way of doing this. the 'gg' of ggplot2 stands for grammar of graphics which refers to a [book](https://link.springer.com/book/10.1007/0-387-28695-0) outlining a logical way of organising graphs. This has developed into a highly versatile program, which although seemingly clunky at first, can rapidly create awesome graphs and dig you out of sticky situations. Again, [ourcodingclub](https://ourcodingclub.github.io/tutorials/) has wonderful tutorials on it. Start [here](https://ourcodingclub.github.io/2017/01/29/datavis.html) then move to [this](https://ourcodingclub.github.io/2017/03/29/data-vis-2.html).\n",
    "\n",
    "### Task 1: Tidyverse Tutorial\n",
    "Thankfully for you (but mainly for me), a summer stundent named Alex cleared up a lovely datset from Sun et al 2013 for you guys to use. Pull down the latest version of this repo and lets get started! Try to complete all the different sections of this task in one file, using git to manage the next version as you finish one task and move onto the next. \n",
    "\n",
    "1) Import the decay rate data dr_data.csv and synthesis rate data sr_data.csv from the ./data folder\n",
    "2) Create code to calculate the mean decay/synthesis rates for each gene across all of its mutants.\n",
    "3) Can you create a single table of genes who have at least one mutant with a significantly changed decay rate or synthesis rate? Can you get it to record the number of significant mutants for each gene?\n",
    "4) Make another table with one row per gene but with the logfold decay/synthesis rates across all mutants along the columns\n",
    "5) Plot a ggplot2 graph (with legend, x/y labels and title) of logfolds across all mutants for the top 5 genes with the highest mean synthesis/decay rates. Ensure the genes are colour coded!\n",
    "![Example Graph](./data/taskOnePlot.jpeg)\n",
    "## String Searching \n",
    "Rather obviously, huge swaths of data are stored in the versatle yet disordered string variable type. Compared to matrices of numbers, whose indices uniquely map elements with logically traceable relationships, strings tend to be massive dumps of various variable types and explanatory comments. In essence, strings are vital for human understanding but entirely intractable for computers. A fair amount of data analysis tasks revolve around slicing exceptionally long strings into computer edible chunks for further analysis. You could create painfully complex logic expressions with numerous nested for/if/while loops to account for every conceivable mispelling or capital letter. Or fortunately for us, we can familarise ourselves with the relatively universal syntax for searching for common structure and their similar variations in strings. \n",
    "\n",
    "Regex (or regular expressions) are available, in some form, for all programming languages. They allow you to outline specific patterns (such as an individual words) together with allowed variants (such as misspelling or cultural varitions or ignoring capitalisation) and even more complex local environment conditions (such as only after a full stop or newline). The underlying algorithms then produce and execute the required logic (very often in a more efficient manner then you could possible have done). \n",
    "\n",
    "```R\n",
    "library(stringr)\n",
    "\n",
    "# Search for the two spellings of aluminium\n",
    "regex(\"alumin(|i)um\")\n",
    "\n",
    "str <- \"Is it aluminium or aluminum!\"\n",
    "str_extract_all(str,regex(\"alumin(|i)um\"))\n",
    "```\n",
    "\n",
    "Please go through [R for Data Science's](https://r4ds.had.co.nz/strings.html#introduction-8) tutorial on regex for a more complete overview.\n",
    "\n",
    "### Task 2: Regex Tutorial\n",
    "\n",
    "1) Import the txt file holding S.cerevisiae chromosome 7 from the ./data folder\n",
    "2) How many times does the TGTTGGAATA motif arise in the chromosome?\n",
    "3) What is most common base pair after/before this motif?\n",
    "4) Can you create a search to look for single nucleotide mutant of this motif?\n",
    "\n",
    "## Standard Statistical Tools\n",
    "As you have probabiliy noticed now in the various papers you have read, there are some standard methods for quantifying the different aspects of your data such as the significance of a particular result or the variance associated with your results. We will now briefly cover some of these tools; $R^{2}$, $CV$, Z-values, t-values / t-test.\n",
    "\n",
    "## Investigating Variation\n",
    "\n",
    "### $R^2$\n",
    "Otherwise known as the coefficient of determination, $R^2$ is defined by\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\text{Residual Sum of Squares}}{\\text{Total Sum of Squares}} = 1 - \\frac{\\text{SS}_{\\text{res}}}{\\text{SS}_{\\text{tot}}}.$$\n",
    "\n",
    "The total sum of squares is the standard sum of the difference between the observed values and the mean squared,\n",
    "\n",
    "$$ \\text{SS}_{\\text{tot}} = \\sum_i (y_i - \\bar y)^2.$$\n",
    "\n",
    "\n",
    "Residual Sum of Squares is the sum of the residuals squared,\n",
    "\n",
    "$$ \\text{SS}_{\\text{res}} = \\sum_i (y_i - f_i)^2.$$\n",
    "\n",
    "Where $f_i$ is the value your model produces for the same point.\n",
    "\n",
    "$\\text{SS}_{\\text{tot}}$ is directly proportional to the total variance of the data collected. Meanwhile $ \\text{SS}_{\\text{res}}$ relates the variance of the data about the model. \n",
    "\n",
    "Therefore $R^2$ is a point statistic giving the percentage of the variance in the data accounted by the model. An $R^2$ of 0.45 means the model covers $45\\%$ of the variance in the data but $55\\%$ comes from a different source. \n",
    "\n",
    "$R^2$ is a poor statistic to use to decide if your model is good / fits well. A low $R^2$ does not imply you have created the wrong model, you could be creating the best model possible given the data available. There could just be, and often are, many different factors affecting the results. In addition it does not account for any bias in the model (i.e. fitting certain parts of your data better than others). \n",
    "\n",
    "### $CV$\n",
    "\n",
    "Otherwise known as the coefficient of variation, $CV$ is defined by\n",
    "$$CV = \\frac{\\sigma}{\\mu}.$$\n",
    "It is the ratio of standard deviation to the mean of the sample. It is a dimensionless quantity, therefore different samples measured with different units can be easily compared. Although care has be taken to ensure the different units have the same scale.\n",
    "\n",
    "## Investigating Correlation\n",
    "If you want to determine if the value of one continuous random variable is linearly related to value of another continuous random variable there are two common test statistics\n",
    "\n",
    "### Pearson Correlation Coefficient\n",
    "Defined as the covariance of the two variables divided by the product of their standard deviations;\n",
    "$$\\rho_{XY} = \\frac{\\text{cov}(X,Y)}{\\sigma_X\\sigma_Y}$$\n",
    "The covariance can be equally defined by;\n",
    "$$\\text{cov}(X,Y) = E((X-\\mu_X)(Y-\\mu_Y)) = E(XY)-E(X)E(Y)$$\n",
    "\n",
    "You get a value between 1 and -1. 1 means perfectally positively correlated, -1 mean perfectly negatively correlated and 0 means not correlated.\n",
    "\n",
    "The biggest issue with the Pearson correlation coefficient is that it is not robust. In this case robustness refers to the effect of having a small fraction of outliers in your data. The Pearson correlation coefficient can be highly sensitive to outliers. This could lead to unfairly low correlation figures, so you should always plot the data when calculate this coefficient.\n",
    "\n",
    "The Pearson correlation coefficient works ideally when the two random variable are normally distributed.\n",
    "\n",
    "### Spearman Correlation Coefficient\n",
    "\n",
    "Very similar in name and approach but with an especially significant difference. Instead of working directly with the record observations of the two random variables, you first rank the observations of the variables and calculate a Pearson correlation coefficient on the ranked values.\n",
    "$$\\rho_{r_Xr_Y} = \\frac{\\text{cov}(r_X,r_Y)}{\\sigma_{r_X}\\sigma_{r_Y}}$$\n",
    "\n",
    "How to convert observations of a random variable to their ranked values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "✔ ggplot2 3.1.0     ✔ purrr   0.2.5\n",
      "✔ tibble  2.0.1     ✔ dplyr   0.7.8\n",
      "✔ tidyr   0.8.2     ✔ stringr 1.3.1\n",
      "✔ readr   1.3.1     ✔ forcats 0.3.0\n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X</th><th scope=col>Y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1.74227585</td><td> 5.6069438 </td></tr>\n",
       "\t<tr><td>-4.08401053</td><td> 3.6432761 </td></tr>\n",
       "\t<tr><td>-0.23240487</td><td> 5.0254147 </td></tr>\n",
       "\t<tr><td>-4.92746233</td><td> 1.6046655 </td></tr>\n",
       "\t<tr><td>-3.83322512</td><td> 5.6339988 </td></tr>\n",
       "\t<tr><td> 6.55064551</td><td> 2.3248892 </td></tr>\n",
       "\t<tr><td> 4.50800958</td><td> 3.9484969 </td></tr>\n",
       "\t<tr><td> 0.09432736</td><td> 2.5993603 </td></tr>\n",
       "\t<tr><td>-3.14838822</td><td> 2.9487848 </td></tr>\n",
       "\t<tr><td>-2.67778834</td><td> 3.7553284 </td></tr>\n",
       "\t<tr><td> 1.63549176</td><td> 1.1448672 </td></tr>\n",
       "\t<tr><td> 5.07681163</td><td> 2.0350613 </td></tr>\n",
       "\t<tr><td>-0.59386221</td><td> 5.0203877 </td></tr>\n",
       "\t<tr><td>-1.50464678</td><td> 2.1031606 </td></tr>\n",
       "\t<tr><td> 4.13721793</td><td> 1.7353685 </td></tr>\n",
       "\t<tr><td> 7.82494484</td><td> 7.1871060 </td></tr>\n",
       "\t<tr><td>-1.77464187</td><td> 2.4653737 </td></tr>\n",
       "\t<tr><td> 0.78249686</td><td>-1.9458957 </td></tr>\n",
       "\t<tr><td>-3.25074544</td><td> 3.9295528 </td></tr>\n",
       "\t<tr><td> 2.49917319</td><td> 0.6832587 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " X & Y\\\\\n",
       "\\hline\n",
       "\t  1.74227585 &  5.6069438 \\\\\n",
       "\t -4.08401053 &  3.6432761 \\\\\n",
       "\t -0.23240487 &  5.0254147 \\\\\n",
       "\t -4.92746233 &  1.6046655 \\\\\n",
       "\t -3.83322512 &  5.6339988 \\\\\n",
       "\t  6.55064551 &  2.3248892 \\\\\n",
       "\t  4.50800958 &  3.9484969 \\\\\n",
       "\t  0.09432736 &  2.5993603 \\\\\n",
       "\t -3.14838822 &  2.9487848 \\\\\n",
       "\t -2.67778834 &  3.7553284 \\\\\n",
       "\t  1.63549176 &  1.1448672 \\\\\n",
       "\t  5.07681163 &  2.0350613 \\\\\n",
       "\t -0.59386221 &  5.0203877 \\\\\n",
       "\t -1.50464678 &  2.1031606 \\\\\n",
       "\t  4.13721793 &  1.7353685 \\\\\n",
       "\t  7.82494484 &  7.1871060 \\\\\n",
       "\t -1.77464187 &  2.4653737 \\\\\n",
       "\t  0.78249686 & -1.9458957 \\\\\n",
       "\t -3.25074544 &  3.9295528 \\\\\n",
       "\t  2.49917319 &  0.6832587 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| X | Y |\n",
       "|---|---|\n",
       "|  1.74227585 |  5.6069438  |\n",
       "| -4.08401053 |  3.6432761  |\n",
       "| -0.23240487 |  5.0254147  |\n",
       "| -4.92746233 |  1.6046655  |\n",
       "| -3.83322512 |  5.6339988  |\n",
       "|  6.55064551 |  2.3248892  |\n",
       "|  4.50800958 |  3.9484969  |\n",
       "|  0.09432736 |  2.5993603  |\n",
       "| -3.14838822 |  2.9487848  |\n",
       "| -2.67778834 |  3.7553284  |\n",
       "|  1.63549176 |  1.1448672  |\n",
       "|  5.07681163 |  2.0350613  |\n",
       "| -0.59386221 |  5.0203877  |\n",
       "| -1.50464678 |  2.1031606  |\n",
       "|  4.13721793 |  1.7353685  |\n",
       "|  7.82494484 |  7.1871060  |\n",
       "| -1.77464187 |  2.4653737  |\n",
       "|  0.78249686 | -1.9458957  |\n",
       "| -3.25074544 |  3.9295528  |\n",
       "|  2.49917319 |  0.6832587  |\n",
       "\n"
      ],
      "text/plain": [
       "   X           Y         \n",
       "1   1.74227585  5.6069438\n",
       "2  -4.08401053  3.6432761\n",
       "3  -0.23240487  5.0254147\n",
       "4  -4.92746233  1.6046655\n",
       "5  -3.83322512  5.6339988\n",
       "6   6.55064551  2.3248892\n",
       "7   4.50800958  3.9484969\n",
       "8   0.09432736  2.5993603\n",
       "9  -3.14838822  2.9487848\n",
       "10 -2.67778834  3.7553284\n",
       "11  1.63549176  1.1448672\n",
       "12  5.07681163  2.0350613\n",
       "13 -0.59386221  5.0203877\n",
       "14 -1.50464678  2.1031606\n",
       "15  4.13721793  1.7353685\n",
       "16  7.82494484  7.1871060\n",
       "17 -1.77464187  2.4653737\n",
       "18  0.78249686 -1.9458957\n",
       "19 -3.25074544  3.9295528\n",
       "20  2.49917319  0.6832587"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "# Consider these variables\n",
    "observations <- tibble(X = rnorm(20,0,4), Y = rnorm(20,3,2))\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First put the observations in ascending order and assign them a number/rank (1 being the lowest value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X</th><th scope=col>Y</th><th scope=col>X_rank</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-4.92746233</td><td> 1.6046655 </td><td> 1         </td></tr>\n",
       "\t<tr><td>-4.08401053</td><td> 3.6432761 </td><td> 2         </td></tr>\n",
       "\t<tr><td>-3.83322512</td><td> 5.6339988 </td><td> 3         </td></tr>\n",
       "\t<tr><td>-3.25074544</td><td> 3.9295528 </td><td> 4         </td></tr>\n",
       "\t<tr><td>-3.14838822</td><td> 2.9487848 </td><td> 5         </td></tr>\n",
       "\t<tr><td>-2.67778834</td><td> 3.7553284 </td><td> 6         </td></tr>\n",
       "\t<tr><td>-1.77464187</td><td> 2.4653737 </td><td> 7         </td></tr>\n",
       "\t<tr><td>-1.50464678</td><td> 2.1031606 </td><td> 8         </td></tr>\n",
       "\t<tr><td>-0.59386221</td><td> 5.0203877 </td><td> 9         </td></tr>\n",
       "\t<tr><td>-0.23240487</td><td> 5.0254147 </td><td>10         </td></tr>\n",
       "\t<tr><td> 0.09432736</td><td> 2.5993603 </td><td>11         </td></tr>\n",
       "\t<tr><td> 0.78249686</td><td>-1.9458957 </td><td>12         </td></tr>\n",
       "\t<tr><td> 1.63549176</td><td> 1.1448672 </td><td>13         </td></tr>\n",
       "\t<tr><td> 1.74227585</td><td> 5.6069438 </td><td>14         </td></tr>\n",
       "\t<tr><td> 2.49917319</td><td> 0.6832587 </td><td>15         </td></tr>\n",
       "\t<tr><td> 4.13721793</td><td> 1.7353685 </td><td>16         </td></tr>\n",
       "\t<tr><td> 4.50800958</td><td> 3.9484969 </td><td>17         </td></tr>\n",
       "\t<tr><td> 5.07681163</td><td> 2.0350613 </td><td>18         </td></tr>\n",
       "\t<tr><td> 6.55064551</td><td> 2.3248892 </td><td>19         </td></tr>\n",
       "\t<tr><td> 7.82494484</td><td> 7.1871060 </td><td>20         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " X & Y & X\\_rank\\\\\n",
       "\\hline\n",
       "\t -4.92746233 &  1.6046655  &  1         \\\\\n",
       "\t -4.08401053 &  3.6432761  &  2         \\\\\n",
       "\t -3.83322512 &  5.6339988  &  3         \\\\\n",
       "\t -3.25074544 &  3.9295528  &  4         \\\\\n",
       "\t -3.14838822 &  2.9487848  &  5         \\\\\n",
       "\t -2.67778834 &  3.7553284  &  6         \\\\\n",
       "\t -1.77464187 &  2.4653737  &  7         \\\\\n",
       "\t -1.50464678 &  2.1031606  &  8         \\\\\n",
       "\t -0.59386221 &  5.0203877  &  9         \\\\\n",
       "\t -0.23240487 &  5.0254147  & 10         \\\\\n",
       "\t  0.09432736 &  2.5993603  & 11         \\\\\n",
       "\t  0.78249686 & -1.9458957  & 12         \\\\\n",
       "\t  1.63549176 &  1.1448672  & 13         \\\\\n",
       "\t  1.74227585 &  5.6069438  & 14         \\\\\n",
       "\t  2.49917319 &  0.6832587  & 15         \\\\\n",
       "\t  4.13721793 &  1.7353685  & 16         \\\\\n",
       "\t  4.50800958 &  3.9484969  & 17         \\\\\n",
       "\t  5.07681163 &  2.0350613  & 18         \\\\\n",
       "\t  6.55064551 &  2.3248892  & 19         \\\\\n",
       "\t  7.82494484 &  7.1871060  & 20         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| X | Y | X_rank |\n",
       "|---|---|---|\n",
       "| -4.92746233 |  1.6046655  |  1          |\n",
       "| -4.08401053 |  3.6432761  |  2          |\n",
       "| -3.83322512 |  5.6339988  |  3          |\n",
       "| -3.25074544 |  3.9295528  |  4          |\n",
       "| -3.14838822 |  2.9487848  |  5          |\n",
       "| -2.67778834 |  3.7553284  |  6          |\n",
       "| -1.77464187 |  2.4653737  |  7          |\n",
       "| -1.50464678 |  2.1031606  |  8          |\n",
       "| -0.59386221 |  5.0203877  |  9          |\n",
       "| -0.23240487 |  5.0254147  | 10          |\n",
       "|  0.09432736 |  2.5993603  | 11          |\n",
       "|  0.78249686 | -1.9458957  | 12          |\n",
       "|  1.63549176 |  1.1448672  | 13          |\n",
       "|  1.74227585 |  5.6069438  | 14          |\n",
       "|  2.49917319 |  0.6832587  | 15          |\n",
       "|  4.13721793 |  1.7353685  | 16          |\n",
       "|  4.50800958 |  3.9484969  | 17          |\n",
       "|  5.07681163 |  2.0350613  | 18          |\n",
       "|  6.55064551 |  2.3248892  | 19          |\n",
       "|  7.82494484 |  7.1871060  | 20          |\n",
       "\n"
      ],
      "text/plain": [
       "   X           Y          X_rank\n",
       "1  -4.92746233  1.6046655  1    \n",
       "2  -4.08401053  3.6432761  2    \n",
       "3  -3.83322512  5.6339988  3    \n",
       "4  -3.25074544  3.9295528  4    \n",
       "5  -3.14838822  2.9487848  5    \n",
       "6  -2.67778834  3.7553284  6    \n",
       "7  -1.77464187  2.4653737  7    \n",
       "8  -1.50464678  2.1031606  8    \n",
       "9  -0.59386221  5.0203877  9    \n",
       "10 -0.23240487  5.0254147 10    \n",
       "11  0.09432736  2.5993603 11    \n",
       "12  0.78249686 -1.9458957 12    \n",
       "13  1.63549176  1.1448672 13    \n",
       "14  1.74227585  5.6069438 14    \n",
       "15  2.49917319  0.6832587 15    \n",
       "16  4.13721793  1.7353685 16    \n",
       "17  4.50800958  3.9484969 17    \n",
       "18  5.07681163  2.0350613 18    \n",
       "19  6.55064551  2.3248892 19    \n",
       "20  7.82494484  7.1871060 20    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X</th><th scope=col>Y</th><th scope=col>X_rank</th><th scope=col>Y_rank</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0.78249686</td><td>-1.9458957 </td><td>12         </td><td> 1         </td></tr>\n",
       "\t<tr><td> 2.49917319</td><td> 0.6832587 </td><td>15         </td><td> 2         </td></tr>\n",
       "\t<tr><td> 1.63549176</td><td> 1.1448672 </td><td>13         </td><td> 3         </td></tr>\n",
       "\t<tr><td>-4.92746233</td><td> 1.6046655 </td><td> 1         </td><td> 4         </td></tr>\n",
       "\t<tr><td> 4.13721793</td><td> 1.7353685 </td><td>16         </td><td> 5         </td></tr>\n",
       "\t<tr><td> 5.07681163</td><td> 2.0350613 </td><td>18         </td><td> 6         </td></tr>\n",
       "\t<tr><td>-1.50464678</td><td> 2.1031606 </td><td> 8         </td><td> 7         </td></tr>\n",
       "\t<tr><td> 6.55064551</td><td> 2.3248892 </td><td>19         </td><td> 8         </td></tr>\n",
       "\t<tr><td>-1.77464187</td><td> 2.4653737 </td><td> 7         </td><td> 9         </td></tr>\n",
       "\t<tr><td> 0.09432736</td><td> 2.5993603 </td><td>11         </td><td>10         </td></tr>\n",
       "\t<tr><td>-3.14838822</td><td> 2.9487848 </td><td> 5         </td><td>11         </td></tr>\n",
       "\t<tr><td>-4.08401053</td><td> 3.6432761 </td><td> 2         </td><td>12         </td></tr>\n",
       "\t<tr><td>-2.67778834</td><td> 3.7553284 </td><td> 6         </td><td>13         </td></tr>\n",
       "\t<tr><td>-3.25074544</td><td> 3.9295528 </td><td> 4         </td><td>14         </td></tr>\n",
       "\t<tr><td> 4.50800958</td><td> 3.9484969 </td><td>17         </td><td>15         </td></tr>\n",
       "\t<tr><td>-0.59386221</td><td> 5.0203877 </td><td> 9         </td><td>16         </td></tr>\n",
       "\t<tr><td>-0.23240487</td><td> 5.0254147 </td><td>10         </td><td>17         </td></tr>\n",
       "\t<tr><td> 1.74227585</td><td> 5.6069438 </td><td>14         </td><td>18         </td></tr>\n",
       "\t<tr><td>-3.83322512</td><td> 5.6339988 </td><td> 3         </td><td>19         </td></tr>\n",
       "\t<tr><td> 7.82494484</td><td> 7.1871060 </td><td>20         </td><td>20         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " X & Y & X\\_rank & Y\\_rank\\\\\n",
       "\\hline\n",
       "\t  0.78249686 & -1.9458957  & 12          &  1         \\\\\n",
       "\t  2.49917319 &  0.6832587  & 15          &  2         \\\\\n",
       "\t  1.63549176 &  1.1448672  & 13          &  3         \\\\\n",
       "\t -4.92746233 &  1.6046655  &  1          &  4         \\\\\n",
       "\t  4.13721793 &  1.7353685  & 16          &  5         \\\\\n",
       "\t  5.07681163 &  2.0350613  & 18          &  6         \\\\\n",
       "\t -1.50464678 &  2.1031606  &  8          &  7         \\\\\n",
       "\t  6.55064551 &  2.3248892  & 19          &  8         \\\\\n",
       "\t -1.77464187 &  2.4653737  &  7          &  9         \\\\\n",
       "\t  0.09432736 &  2.5993603  & 11          & 10         \\\\\n",
       "\t -3.14838822 &  2.9487848  &  5          & 11         \\\\\n",
       "\t -4.08401053 &  3.6432761  &  2          & 12         \\\\\n",
       "\t -2.67778834 &  3.7553284  &  6          & 13         \\\\\n",
       "\t -3.25074544 &  3.9295528  &  4          & 14         \\\\\n",
       "\t  4.50800958 &  3.9484969  & 17          & 15         \\\\\n",
       "\t -0.59386221 &  5.0203877  &  9          & 16         \\\\\n",
       "\t -0.23240487 &  5.0254147  & 10          & 17         \\\\\n",
       "\t  1.74227585 &  5.6069438  & 14          & 18         \\\\\n",
       "\t -3.83322512 &  5.6339988  &  3          & 19         \\\\\n",
       "\t  7.82494484 &  7.1871060  & 20          & 20         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| X | Y | X_rank | Y_rank |\n",
       "|---|---|---|---|\n",
       "|  0.78249686 | -1.9458957  | 12          |  1          |\n",
       "|  2.49917319 |  0.6832587  | 15          |  2          |\n",
       "|  1.63549176 |  1.1448672  | 13          |  3          |\n",
       "| -4.92746233 |  1.6046655  |  1          |  4          |\n",
       "|  4.13721793 |  1.7353685  | 16          |  5          |\n",
       "|  5.07681163 |  2.0350613  | 18          |  6          |\n",
       "| -1.50464678 |  2.1031606  |  8          |  7          |\n",
       "|  6.55064551 |  2.3248892  | 19          |  8          |\n",
       "| -1.77464187 |  2.4653737  |  7          |  9          |\n",
       "|  0.09432736 |  2.5993603  | 11          | 10          |\n",
       "| -3.14838822 |  2.9487848  |  5          | 11          |\n",
       "| -4.08401053 |  3.6432761  |  2          | 12          |\n",
       "| -2.67778834 |  3.7553284  |  6          | 13          |\n",
       "| -3.25074544 |  3.9295528  |  4          | 14          |\n",
       "|  4.50800958 |  3.9484969  | 17          | 15          |\n",
       "| -0.59386221 |  5.0203877  |  9          | 16          |\n",
       "| -0.23240487 |  5.0254147  | 10          | 17          |\n",
       "|  1.74227585 |  5.6069438  | 14          | 18          |\n",
       "| -3.83322512 |  5.6339988  |  3          | 19          |\n",
       "|  7.82494484 |  7.1871060  | 20          | 20          |\n",
       "\n"
      ],
      "text/plain": [
       "   X           Y          X_rank Y_rank\n",
       "1   0.78249686 -1.9458957 12      1    \n",
       "2   2.49917319  0.6832587 15      2    \n",
       "3   1.63549176  1.1448672 13      3    \n",
       "4  -4.92746233  1.6046655  1      4    \n",
       "5   4.13721793  1.7353685 16      5    \n",
       "6   5.07681163  2.0350613 18      6    \n",
       "7  -1.50464678  2.1031606  8      7    \n",
       "8   6.55064551  2.3248892 19      8    \n",
       "9  -1.77464187  2.4653737  7      9    \n",
       "10  0.09432736  2.5993603 11     10    \n",
       "11 -3.14838822  2.9487848  5     11    \n",
       "12 -4.08401053  3.6432761  2     12    \n",
       "13 -2.67778834  3.7553284  6     13    \n",
       "14 -3.25074544  3.9295528  4     14    \n",
       "15  4.50800958  3.9484969 17     15    \n",
       "16 -0.59386221  5.0203877  9     16    \n",
       "17 -0.23240487  5.0254147 10     17    \n",
       "18  1.74227585  5.6069438 14     18    \n",
       "19 -3.83322512  5.6339988  3     19    \n",
       "20  7.82494484  7.1871060 20     20    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rank <- c(1:20)\n",
    "# Assign order to X values\n",
    "observations <- observations %>%\n",
    "  arrange(X) %>%\n",
    "  add_column(X_rank = rank)\n",
    "observations\n",
    "\n",
    "# Assign order to Y values\n",
    "observations <- observations %>%\n",
    "  arrange(Y) %>%\n",
    "  add_column(Y_rank = rank)\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then conduct a normal Pearson correlation coefficient calculation on the ranked values of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>X</th><th scope=col>Y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>X</th><td> 1.00000000</td><td>-0.09022556</td></tr>\n",
       "\t<tr><th scope=row>Y</th><td>-0.09022556</td><td> 1.00000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & X & Y\\\\\n",
       "\\hline\n",
       "\tX &  1.00000000 & -0.09022556\\\\\n",
       "\tY & -0.09022556 &  1.00000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | X | Y |\n",
       "|---|---|---|\n",
       "| X |  1.00000000 | -0.09022556 |\n",
       "| Y | -0.09022556 |  1.00000000 |\n",
       "\n"
      ],
      "text/plain": [
       "  X           Y          \n",
       "X  1.00000000 -0.09022556\n",
       "Y -0.09022556  1.00000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rankData <- data.frame(X = observations$X_rank, Y= observations$Y_rank)\n",
    "cor(rankData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is far more robust, since magnitudes of the observed values are irrelevent only respective orders are used!\n",
    "\n",
    "There is also another crutial benefit to calculating a Pearson correlation coefficient on ranks, the resulting calculation is now non-parametric. You are no longer assuming a linear relationship between X and Y, but the much more liberal constraint of having any form of monotonic function relating X and Y. The importance of non-parametric tests is currently beyond our project but will appear more often if you continue your journey into statistics, particularly if you are conducting statistical tests to proof the significance of a correlation.\n",
    "\n",
    "## Hypothesis Tests\n",
    "These test revolve around calculating the probability of getting the sample observations obtained given your hypotheses about the parameters of the population distribution.\n",
    "\n",
    "### Student's t-tests\n",
    "If you are reasonably sure the population distribution is normally distributed then the Student's t-test is a common way of testing your population distribution hypotheses. Normality  is often a relatively uncontrovertial assumption because many distribtuions can be approximated by a normal distribution (although definitely not all and definitely not all the time!).  \n",
    "\n",
    "In an ideal world if you think you sample is from a normal distribution then you should use a normal distribution to conduct your hypothesis test. However, practical limitations often cause you to take such small sample sizes that normal distribution based test is unwise. Instead, it is common practise to use a squished normal distribution, called a Student's t-distribution.\n",
    "\n",
    "$$T = \\mathcal{N} \\sqrt{\\frac{v}{V}}$$\n",
    "With $\\mathcal{N}$ being a standard normal distribution $\\mathcal{N}(0,1)$, $v$ is the degrees of freedom and $V$ is the $\\chi^2$ distribution.\n",
    "\n",
    "For obvious reasons this distribution is horrible to calculate, so is often only encountered through tables and tables of pre-calculated values. Again, because the t-distribution is horrible to calculate all t-values are calculated from a normal distribution with mean 0, variance 1. Therefore, whenever you conduct a t-test the first step is to scale your observered data down to their values if taken from a normal distribution. \n",
    "$$\\mathcal{N}(0,1) \\equiv \\frac {\\mathcal{N}(\\mu,\\sigma) - \\mu}{\\sigma}$$\n",
    "\n",
    "So if you have a set of values sampled from an arbitrary normal distribution you can rescale them to values from a unit normal distribution;\n",
    "$$\\mathbf{X}\\sim\\mathcal{N}(\\mu,\\sigma)$$\n",
    "\n",
    "$$\\equiv$$\n",
    "$$\\frac {\\mathbf{X} - \\mu}{\\sigma}\\sim \\mathcal{N}(0,1)$$\n",
    "\n",
    "Then you can work out the probability of getting your scaled data from a standard normal distribution under the limited degrees of freedom in you experiment using Student's t-distribution tables (or just a function which computes all of this for you).\n",
    "\n",
    "I wish mainly to retract what a said about the AIC bring a special case of the likelihood ratio test. That was wrong.\n",
    "\n",
    "Instead, what I have should have said is that, with the 4 motif models we are currently comparing, they are essentially equivalent. When we begin to compare models with different numbers of parameters, their results will diverge. \n",
    "\n",
    "## AIC\n",
    "\n",
    "AIC is defined by\n",
    "\n",
    "$$2k - 2ln(\\hat{\\mathcal{L}})$$\n",
    "where $k$ is the number of parameters and $\\hat{\\mathcal{L}}$ is the maximum likelihood estimate of the parameters given the data.\n",
    "\n",
    "## Likelihood ratio\n",
    "\n",
    "Likelihood ratio is defined by \n",
    "\n",
    "$$\\lambda = \\frac{\\mathcal{L}_a}{\\mathcal{L}_b}$$\n",
    "where $\\mathcal{L}_a$ and $\\mathcal{L}_b$ are the likelihoods given different parameters/parameter values.\n",
    "\n",
    "## Test\n",
    "You can arbitrarily choose a value to select one model over another by saying the difference in the AIC values is greater then 5 or that $\\lambda$ is less than some parameter $\\alpha$.\n",
    "\n",
    "In our case, when we compare models with the same parameters (just different values), we get\n",
    "\n",
    "$$\\Delta \\text{AIC} = 2k - 2ln(\\hat{\\mathcal{L}}_a) - 2k + 2ln(\\hat{\\mathcal{L}}_b)\\lt5$$\n",
    "$$\\Delta \\text{AIC} = -2ln\\Bigg(\\frac{\\hat{\\mathcal{L}}_a}{\\hat{\\mathcal{L}}_b}\\Bigg)<5$$\n",
    "\n",
    "$$ \\frac{\\hat{\\mathcal{L}}_a}{\\hat{\\mathcal{L}}_b} < e^{-2.5}.$$\n",
    "Which is just a likelihood ratio test with $\\alpha = e^{-2.5}$!!\n",
    "\n",
    "## Likelihoods of models with different parameters\n",
    "\n",
    "You can calculate the AIC for any model's maximum likelihood and compare. If we have different numbers of parameters then the k's don't cancel out and the above calculation doesn't work. The $2ln()$ part is derived from information theory, which we will not go into here, but feel free to explore that if you want! Its very interesting.\n",
    "\n",
    "The likelihood ratio test has a strong constraint that the one model, with fewer parameters, must be nested in the model with more parameters! That is to say, all the terms in the simpler model must be present in the larger one (although with different values). In our current case, the two models have identical parameters and so are nestable either way!\n",
    "\n",
    "## Calculation of AIC/ratio for the linear models\n",
    "\n",
    "All you need to know now is the maximum likelihood estimates for the linear models calculated! How to find them out? \n",
    "\n",
    "Linear model algorithms can use the maximum likelihood estimates to deduce the values of the parameters and their standard deviations.\n",
    "\n",
    "For various computational and mathematical considerations R's lm algorithm uses ordinary least squares to calculate its mean and variance. OLS can be shown to equal the maximum likelihood estimate for many cases (error is normally distributed). However, using OLS directly is more stable for when normallity is lost. \n",
    "\n",
    "An easy way to extract the loglikelihood term is with logLik\n",
    "```r\n",
    "library(tidyverse)\n",
    "data <- tibble (x = rnorm(100),y = rnorm(100) * 3)\n",
    "model = lm(x~y, data)\n",
    "logLikelihood = logLik(model)\n",
    "logLikelihood\n",
    "```\n",
    "This is calculating \n",
    "$$log(\\mathcal{L}) = log\\Big(\\sum_D P(D|\\hat \\mu,\\hat \\sigma)\\Big)=log \\Bigg(\\sum_D \\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-\\frac{(D - \\hat \\mu)^2}{2\\hat \\sigma}}\\Bigg)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
